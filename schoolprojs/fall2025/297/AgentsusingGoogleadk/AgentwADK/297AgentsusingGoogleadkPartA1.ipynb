{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "032dd603627f476f8b11c5ca399b7749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c199a97fd0347f9b85700884400b93f",
              "IPY_MODEL_d4c9e40a35d3482fbaf18643c27bcdb5",
              "IPY_MODEL_ad11d2a9fa84422ba4e93f3419a12586"
            ],
            "layout": "IPY_MODEL_95df4e85a7ca439293f9c03fb7ac56ea"
          }
        },
        "6c199a97fd0347f9b85700884400b93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45afb18b3a3436c8f896b173927a7dd",
            "placeholder": "​",
            "style": "IPY_MODEL_bd5be8b0caeb43bf9373f127b5b4a7f3",
            "value": "deepseek-coder-6.7b-instruct.Q4_K_M.gguf: 100%"
          }
        },
        "d4c9e40a35d3482fbaf18643c27bcdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c742ae930f4058b65b31c01d5bfd63",
            "max": 4083015904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d53f45e2991c4e3fb2b0947767a06bda",
            "value": 4083015904
          }
        },
        "ad11d2a9fa84422ba4e93f3419a12586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85504fa60f874c4186ffeb1aee8de2ff",
            "placeholder": "​",
            "style": "IPY_MODEL_980c1483fe8d45d889ea2a840c72d660",
            "value": " 4.08G/4.08G [01:32&lt;00:00, 48.2MB/s]"
          }
        },
        "95df4e85a7ca439293f9c03fb7ac56ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45afb18b3a3436c8f896b173927a7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5be8b0caeb43bf9373f127b5b4a7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85c742ae930f4058b65b31c01d5bfd63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53f45e2991c4e3fb2b0947767a06bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85504fa60f874c4186ffeb1aee8de2ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980c1483fe8d45d889ea2a840c72d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "btBwyenHEQWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afc2974-4aa7-477d-d83f-ace16f0374fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install google-adk litellm huggingface_hub llama-cpp-python==0.2.84 python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# DeepSeek-Coder 6.7B Instruct (quantized GGUF) – good balance of quality/speed\n",
        "REPO_ID = \"TheBloke/DeepSeek-Coder-6.7B-Instruct-GGUF\"\n",
        "FILENAME = \"deepseek-coder-6.7b-instruct.Q4_K_M.gguf\"\n",
        "\n",
        "model_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)\n",
        "model_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "032dd603627f476f8b11c5ca399b7749",
            "6c199a97fd0347f9b85700884400b93f",
            "d4c9e40a35d3482fbaf18643c27bcdb5",
            "ad11d2a9fa84422ba4e93f3419a12586",
            "95df4e85a7ca439293f9c03fb7ac56ea",
            "a45afb18b3a3436c8f896b173927a7dd",
            "bd5be8b0caeb43bf9373f127b5b4a7f3",
            "85c742ae930f4058b65b31c01d5bfd63",
            "d53f45e2991c4e3fb2b0947767a06bda",
            "85504fa60f874c4186ffeb1aee8de2ff",
            "980c1483fe8d45d889ea2a840c72d660"
          ]
        },
        "id": "5Qeoj5RuNwK0",
        "outputId": "82c189aa-bc96-4b3b-a43b-411910c619c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "deepseek-coder-6.7b-instruct.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "032dd603627f476f8b11c5ca399b7749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--TheBloke--DeepSeek-Coder-6.7B-Instruct-GGUF/snapshots/9e221e6b41cb1bf1c5d8f9718e81e3dc781f7557/deepseek-coder-6.7b-instruct.Q4_K_M.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade \"llama-cpp-python[server]==0.2.84\"\n"
      ],
      "metadata": {
        "id": "55TrbT2rS1Aw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this once so the next bash cell can see the path\n",
        "import os\n",
        "os.environ[\"MODEL_PATH\"] = model_path  # model_path comes from Step 2\n",
        "print(\"Using model at:\", os.environ[\"MODEL_PATH\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqAS7vq9SPm_",
        "outputId": "877023dc-d0fd-4bc7-f589-358d28df55fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model at: /root/.cache/huggingface/hub/models--TheBloke--DeepSeek-Coder-6.7B-Instruct-GGUF/snapshots/9e221e6b41cb1bf1c5d8f9718e81e3dc781f7557/deepseek-coder-6.7b-instruct.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "print(requests.get(\"http://127.0.0.1:8000/v1/models\", timeout=5).json())\n"
      ],
      "metadata": {
        "id": "Ke7Bec0PbdIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 3.A1 — start server in background and log to /content/server.log\n",
        "pkill -f \"llama_cpp.server.*--port 8000\" || true\n",
        "\n",
        "nohup python -m llama_cpp.server \\\n",
        "  --model \"$MODEL_PATH\" \\\n",
        "  --host 127.0.0.1 --port 8000 \\\n",
        "  --model_alias deepseek-local \\\n",
        "  --chat_format chatml \\\n",
        "  --n_ctx 4096 \\\n",
        "  > /content/server.log 2>&1 &\n",
        "\n",
        "sleep 3\n",
        "tail -n 50 /content/server.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9FvdOUCcct3",
        "outputId": "63d8602c-155b-4c5b-a289-8757264247f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 100000.0\n",
            "llm_load_print_meta: freq_scale_train = 0.25\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 16384\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = deepseek-ai_deepseek-coder-6.7b-instruct\n",
            "llm_load_print_meta: BOS token        = 32013 '<｜begin▁of▁sentence｜>'\n",
            "llm_load_print_meta: EOS token        = 32021 '<|EOT|>'\n",
            "llm_load_print_meta: PAD token        = 32014 '<｜end▁of▁sentence｜>'\n",
            "llm_load_print_meta: LF token         = 126 'Ä'\n",
            "llm_load_print_meta: max token length = 128\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3892.62 MiB\n",
            "warning: failed to mlock 75624448-byte buffer (after previously locking 0 bytes): Cannot allocate memory\n",
            "Try increasing RLIMIT_MEMLOCK ('ulimit -l' as root).\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 100000.0\n",
            "llama_new_context_with_model: freq_scale = 0.25\n",
            "llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '32014', 'tokenizer.ggml.eos_token_id': '32021', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '100000.000000', 'llama.context_length': '16384', 'general.name': 'deepseek-ai_deepseek-coder-6.7b-instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '32013', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'llama.rope.scale_linear': '4.000000', 'general.file_type': '15'}\n",
            "INFO:     Started server process [17009]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.A2 — wait for server to be ready\n",
        "import time, requests, subprocess\n",
        "\n",
        "base = \"http://127.0.0.1:8000\"\n",
        "for i in range(120):  # up to ~6 minutes on CPU\n",
        "    try:\n",
        "        r = requests.get(f\"{base}/v1/models\", timeout=2)\n",
        "        if r.ok:\n",
        "            print(\"Server is ready ✅\")\n",
        "            print(r.json())\n",
        "            break\n",
        "    except Exception:\n",
        "        pass\n",
        "    if i % 5 == 0:\n",
        "        print(f\"...waiting ({i*3}s)\")\n",
        "    time.sleep(3)\n",
        "else:\n",
        "    print(\"Server not ready; last 100 log lines:\")\n",
        "    subprocess.run([\"tail\",\"-n\",\"100\",\"/content/server.log\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD1Aq7d3c2Fe",
        "outputId": "81d4eb69-dca1-4bec-bd8f-91b0600c0b76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server is ready ✅\n",
            "{'object': 'list', 'data': [{'id': 'deepseek-local', 'object': 'model', 'owned_by': 'me', 'permissions': []}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.A3 — set env for ADK/LiteLLM\n",
        "import os\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"http://127.0.0.1:8000/v1\"\n",
        "os.environ[\"OPENAI_API_KEY\"]  = \"sk-local-anything\"  # dummy\n",
        "print(\"Env set. Proceed to the ADK agent + FunctionTool cell.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzNO1Hndc45F",
        "outputId": "3ef0db83-c96c-4d93-a158-cea93356ab7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Env set. Proceed to the ADK agent + FunctionTool cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you haven't yet:\n",
        "# !pip -q install google-adk litellm\n",
        "\n",
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any\n",
        "\n",
        "# ADK bits\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import FunctionTool\n",
        "from google.genai import types\n",
        "\n",
        "# Route ADK → your local OpenAI-compatible server via LiteLLM\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "\n",
        "# ---------- Simple Function Tool ----------\n",
        "@dataclass\n",
        "class BudgetInput:\n",
        "    square_feet: int\n",
        "    finish_level: str  # \"basic\" | \"standard\" | \"premium\"\n",
        "\n",
        "def estimate_kitchen_budget(square_feet: int, finish_level: str) -> Dict[str, Any]:\n",
        "    finish_level = (finish_level or \"standard\").lower().strip()\n",
        "    cost_per_sf = {\"basic\": 150, \"standard\": 300, \"premium\": 600}.get(finish_level, 300)\n",
        "    base = 4000\n",
        "    estimate = base + square_feet * cost_per_sf\n",
        "    line_items = [\n",
        "        {\"item\": \"Design & Permits\", \"cost\": int(0.07 * estimate)},\n",
        "        {\"item\": \"Cabinetry & Millwork\", \"cost\": int(0.30 * estimate)},\n",
        "        {\"item\": \"Appliances\", \"cost\": int(0.18 * estimate)},\n",
        "        {\"item\": \"Counters & Backsplash\", \"cost\": int(0.15 * estimate)},\n",
        "        {\"item\": \"Plumbing & Electrical\", \"cost\": int(0.12 * estimate)},\n",
        "        {\"item\": \"Flooring/Paint/Misc.\", \"cost\": int(0.08 * estimate)},\n",
        "        {\"item\": \"Contingency\", \"cost\": int(0.10 * estimate)},\n",
        "    ]\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"estimate_usd\": int(estimate),\n",
        "        \"finish_level\": finish_level,\n",
        "        \"inputs\": {\"square_feet\": square_feet, \"finish_level\": finish_level},\n",
        "        \"line_items\": line_items,\n",
        "        \"notes\": \"Heuristic only—validate with contractor bids.\",\n",
        "    }\n",
        "\n",
        "budget_tool = FunctionTool(func=estimate_kitchen_budget)\n",
        "\n",
        "# ---------- LLM + Agent ----------\n",
        "# Your server exposed a model with id 'deepseek-local'. LiteLLM uses \"openai/<id>\".\n",
        "local_model = LiteLlm(model=\"openai/deepseek-local\")\n",
        "\n",
        "kitchen_agent = LlmAgent(\n",
        "    model=local_model,\n",
        "    name=\"kitchen_renovation_agent\",\n",
        "    description=\"Creates a concise kitchen renovation proposal and uses a budget estimator tool.\",\n",
        "    instruction=(\n",
        "        \"You are a renovation consultant. Produce a 1-page proposal with sections:\\n\"\n",
        "        \"1) Scope overview; 2) Design concept; 3) Materials (bullets);\\n\"\n",
        "        \"4) Timeline (phases); 5) Budget summary; 6) Disclaimers.\\n\"\n",
        "        \"Always call the tool `estimate_kitchen_budget(square_feet, finish_level)` to compute the budget.\\n\"\n",
        "        \"If the tool returns 'status: success', include total and line items.\\n\"\n",
        "        \"Write clear, structured Markdown. Be practical and specific.\"\n",
        "    ),\n",
        "    tools=[budget_tool],\n",
        ")\n",
        "\n",
        "# ---------- Runner (single turn) ----------\n",
        "APP_NAME = \"adk_kitchen_agent_demo\"\n",
        "USER_ID = \"student\"\n",
        "SESSION_ID = \"session-001\"\n",
        "\n",
        "async def call_agent_once(user_message: str):\n",
        "    session_service = InMemorySessionService()\n",
        "    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
        "    runner = Runner(agent=kitchen_agent, app_name=APP_NAME, session_service=session_service)\n",
        "\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=user_message)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    final_text = None\n",
        "\n",
        "    def extract_text(content_obj):\n",
        "        try:\n",
        "            if content_obj and getattr(content_obj, \"parts\", None):\n",
        "                for p in content_obj.parts:\n",
        "                    t = getattr(p, \"text\", None)\n",
        "                    if t:\n",
        "                        return t\n",
        "        except Exception:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "    for event in events:\n",
        "        # ---- try to print tool request/response if present ----\n",
        "        tool_name = getattr(event, \"tool_name\", None)\n",
        "        parameters = getattr(event, \"parameters\", None)\n",
        "        if tool_name and parameters is not None:\n",
        "            print(\"→ Tool request:\", tool_name, parameters)\n",
        "\n",
        "        # Some versions put tool response into .content; others in .tool_response\n",
        "        tool_resp = getattr(event, \"tool_response\", None)\n",
        "        if tool_resp is not None:\n",
        "            print(\"← Tool response (obj):\", str(tool_resp)[:180], \"...\")\n",
        "        else:\n",
        "            txt = extract_text(getattr(event, \"content\", None))\n",
        "            # Heuristic: if it looks like a JSON/dict from our tool, log a short preview\n",
        "            if txt and (\"estimate_usd\" in txt or \"line_items\" in txt or \"status\" in txt):\n",
        "                print(\"← Tool response (preview):\", txt[:180], \"...\")\n",
        "\n",
        "        # ---- try to capture the latest meaningful assistant text ----\n",
        "        txt = extract_text(getattr(event, \"content\", None))\n",
        "        if txt:\n",
        "            final_text = txt\n",
        "\n",
        "    if final_text:\n",
        "        print(\"\\n===== Agent Final Response =====\\n\")\n",
        "        print(final_text)\n",
        "        return final_text\n",
        "    else:\n",
        "        print(\"No final response (check logs above).\")\n",
        "        return \"\"\n",
        "\n",
        "prompt = (\n",
        "    \"Create a kitchen renovation proposal for a 180 sq ft space, finish level 'standard'. \"\n",
        "    \"The client wants an island with seating for 3, durable quartz counters, and to keep the existing layout if possible. \"\n",
        "    \"Target budget under $45k if feasible.\"\n",
        ")\n",
        "\n",
        "final_md = await call_agent_once(prompt)   # <- works in Colab\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5GnzEmpdaJQ",
        "outputId": "ba3a660c-e9fa-498d-d39f-c076ce183e79"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Agent Final Response =====\n",
            "\n",
            "I'm sorry for any confusion, but as a text-based AI model, I don't have access to an actual budget estimator tool or data about kitchen renovation costs. However, I can provide you with an outline based on your description of the project:\n",
            "\n",
            "1) **Scope Overview**: The scope of the renovation includes a complete redesign of the existing kitchen which consists of a large island with seating for 3 people and durable quartz counters.\n",
            "\n",
            "2) **Design Concept**: The design concept involves incorporating an open-concept countertop, that complements the existing layout nicely. We will also add a high gloss finish to accentuate the space.\n",
            "\n",
            "3) **Materials**: \n",
            "   - Countertops: Durable quartz counters (4) with an open-concept design for increased versatility and functionality.\n",
            "   - Accessories: Tall drawers, compact cabinets with handles for easy access to each item.\n",
            "   - Finish: High gloss finish to make the space appear modern and elegant.\n",
            "\n",
            "4) **Timeline**: \n",
            "   - Design and Planning: A week of planning to ensure all necessary details are taken into consideration.\n",
            "   - Construction: Estimated time based on square footage, materials used, and specific expertise required for each job.\n",
            "   - Installation: The completion of the project will be followed by installation of the new countertops, drawers, etc., which would take another week or two.\n",
            "\n",
            "5) **Budget Summary**: For an estimate, we can provide you with a rough budget that includes costs for materials (both upfront and over time), labor (including expert guidance fees if required), and other potential charges like additional hardware, cleaning, etc. \n",
            "\n",
            "6) **Disclaimers**: As this is just a rough estimation, it may not reflect all expenses due to the uncertainties about material choices, installation schedule, or future costs. Please consult with an actual budget estimator tool for more accurate estimates.\n",
            "\n",
            "Please note that while I strive to provide detailed and clear information, my capabilities are limited to providing an outline based on your description of the project. The final proposal would need to be created by a human professional who is familiar with kitchen renovation procedures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "out_dir = Path(\"/content/agent_outputs\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "out_path = out_dir / f\"proposal_{ts}.md\"\n",
        "out_path.write_text(final_md or \"\")\n",
        "print(\"Saved:\", out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQDI92SeynSE",
        "outputId": "10db9703-370d-439e-ca08-b8dffb35a5ba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/agent_outputs/proposal_20251017-013048.md\n"
          ]
        }
      ]
    }
  ]
}