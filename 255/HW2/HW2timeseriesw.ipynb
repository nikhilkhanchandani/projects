{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c138cd69b56491093a1fd36c6fa3846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aca3b75b4b674afb902b401f62a2477b",
              "IPY_MODEL_906b17f02f6f49e49c6739bd5ee7df52",
              "IPY_MODEL_f887fa706ca14b38b291e2978cc740fe"
            ],
            "layout": "IPY_MODEL_1dc681a572184085a5172f1a7c7e2eed"
          }
        },
        "aca3b75b4b674afb902b401f62a2477b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a72b0d06fb41949a8bb9e11f647ad6",
            "placeholder": "​",
            "style": "IPY_MODEL_d374736e26f145b78e576a59ee9477cd",
            "value": "Processing: 100%"
          }
        },
        "906b17f02f6f49e49c6739bd5ee7df52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870661043ab54de1a5bf36e2893fef54",
            "max": 121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08f3e215ddc14ca9b87033f18ff13ec6",
            "value": 121
          }
        },
        "f887fa706ca14b38b291e2978cc740fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60423e7a0a6e4afbb1c1bb66c5d98b96",
            "placeholder": "​",
            "style": "IPY_MODEL_01c3ca9867914458a982a61b36e8f463",
            "value": " 121/121 [03:48&lt;00:00,  1.81it/s]"
          }
        },
        "1dc681a572184085a5172f1a7c7e2eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f0a72b0d06fb41949a8bb9e11f647ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d374736e26f145b78e576a59ee9477cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "870661043ab54de1a5bf36e2893fef54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f3e215ddc14ca9b87033f18ff13ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60423e7a0a6e4afbb1c1bb66c5d98b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c3ca9867914458a982a61b36e8f463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_3BcJnfPha4",
        "outputId": "64fa54b9-ba88-4aeb-aca1-c728ddeffa51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret[full] in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.66.5)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.26.4)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.1.4)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (3.1.4)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.0.2)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.12.3)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.6.3)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.5.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.1.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (8.4.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.2.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (3.7.1)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (5.15.0)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.2.1)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.14.3)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: shap~=0.44.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.44.1)\n",
            "Requirement already satisfied: interpret>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.6.3)\n",
            "Requirement already satisfied: umap-learn>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.5.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (6.0.2)\n",
            "Requirement already satisfied: ydata-profiling>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.10.0)\n",
            "Requirement already satisfied: explainerdashboard>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.4.7)\n",
            "Requirement already satisfied: fairlearn==0.7.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: kmodes>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.12.2)\n",
            "Requirement already satisfied: mlxtend>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.23.1)\n",
            "Requirement already satisfied: statsforecast<1.6.0,>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.2.7)\n",
            "Requirement already satisfied: optuna>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.0.0)\n",
            "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.0.0)\n",
            "Requirement already satisfied: scikit-optimize>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: mlflow>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.16.2)\n",
            "Requirement already satisfied: gradio>=3.50.2 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.44.0)\n",
            "Requirement already satisfied: boto3>=1.24.56 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.35.24)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.115.0)\n",
            "Requirement already satisfied: uvicorn>=0.17.6 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.30.6)\n",
            "Requirement already satisfied: m2cgen>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: evidently~=0.4.16 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.4.37)\n",
            "Requirement already satisfied: dask>=2024.4.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2024.8.0)\n",
            "Requirement already satisfied: distributed>=2024.4.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2024.8.0)\n",
            "Requirement already satisfied: fugue~=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.8.7)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.0,>=2.2 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.3.8)\n",
            "Requirement already satisfied: pytest<8.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (7.4.4)\n",
            "Requirement already satisfied: moto<5.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (4.2.14)\n",
            "Requirement already satisfied: dash[testing] in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.18.1)\n",
            "Requirement already satisfied: scikit-learn-intelex>=2023.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2024.7.0)\n",
            "Requirement already satisfied: catboost>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (1.2.7)\n",
            "Requirement already satisfied: tune-sklearn>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: ray>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (2.36.0)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pycaret[full]) (2.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret[full]) (24.1)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret[full]) (0.7.8)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.24 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.24.56->pycaret[full]) (1.35.24)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.24.56->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.24.56->pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost>=0.23.2->pycaret[full]) (0.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost>=0.23.2->pycaret[full]) (1.16.0)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret[full]) (0.5.6)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2024.4.1->pycaret[full]) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2024.4.1->pycaret[full]) (2024.6.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2024.4.1->pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2024.4.1->pycaret[full]) (0.12.1)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.0.8)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (2.0.7)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: nltk>=3.6.7 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (3.8.1)\n",
            "Requirement already satisfied: pydantic>=1.10.13 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (2.9.2)\n",
            "Requirement already satisfied: litestar>=2.8.3 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (2.12.1)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.9.0)\n",
            "Requirement already satisfied: watchdog>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (5.0.2)\n",
            "Requirement already satisfied: typer>=0.3 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.12.5)\n",
            "Requirement already satisfied: rich>=13 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (13.8.1)\n",
            "Requirement already satisfied: iterative-telemetry>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.0.9)\n",
            "Requirement already satisfied: dynaconf>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (3.2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (2024.8.30)\n",
            "Requirement already satisfied: ujson>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (5.10.0)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.10/dist-packages (from evidently~=0.4.16->pycaret[full]) (43.0.1)\n",
            "Requirement already satisfied: dash-auth in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.3.0)\n",
            "Requirement already satisfied: dash-bootstrap-components>=1 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.6.0)\n",
            "Requirement already satisfied: dtreeviz>=2.1 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.2.2)\n",
            "Requirement already satisfied: flask-simplelogin in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.1.3)\n",
            "Requirement already satisfied: Flask-WTF>=1.1 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.2.1)\n",
            "Requirement already satisfied: jupyter-dash>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.4.2)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.10/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: triad>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.2.6)\n",
            "Requirement already satisfied: qpd>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.4.4)\n",
            "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.2.2)\n",
            "Requirement already satisfied: sqlglot in /usr/local/lib/python3.10/dist-packages (from fugue~=0.8.0->pycaret[full]) (20.11.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (6.4.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (3.10.7)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (10.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.0.10)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.6.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=3.50.2->pycaret[full]) (4.12.2)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio>=3.50.2->pycaret[full]) (12.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->pycaret[full]) (0.38.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (0.10.9.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret[full]) (3.20.2)\n",
            "Requirement already satisfied: interpret-core==0.6.3 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (0.6.3)\n",
            "Requirement already satisfied: aplr>=10.5.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (10.6.3)\n",
            "Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (5.5.6)\n",
            "Requirement already satisfied: dill>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (0.3.8)\n",
            "Requirement already satisfied: dash-core-components>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-html-components>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-table>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (5.0.0)\n",
            "Requirement already satisfied: dash-cytoscape>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (1.0.2)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (24.2.1)\n",
            "Requirement already satisfied: SALib>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret[full]) (4.9.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[full]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[full]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[full]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[full]) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8.0->pycaret[full]) (2.8.2)\n",
            "Requirement already satisfied: mlflow-skinny==2.16.2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (2.16.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (1.13.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.3)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.7)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (14.0.2)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (2.0.35)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow>=2.0.0->pycaret[full]) (23.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (5.5.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (0.32.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (3.1.43)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (1.27.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (3.20.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->pycaret[full]) (2.2.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (from moto<5.0.0->pycaret[full]) (0.13.0)\n",
            "Requirement already satisfied: responses>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from moto<5.0.0->pycaret[full]) (0.25.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret[full]) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret[full]) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret[full]) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret[full]) (0.43.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->pycaret[full]) (6.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret[full]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0->pycaret[full]) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.14.0->pycaret[full]) (9.0.0)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.1.3)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret[full]) (3.0.11)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0->pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0->pycaret[full]) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest<8.0.0->pycaret[full]) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (3.16.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=1.0.0->ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=1.0.0; (python_version != \"3.11\" and platform_system != \"Windows\") and extra == \"full\"->pycaret[full]) (2.6.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret[full]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret[full]) (3.10)\n",
            "Requirement already satisfied: daal4py==2024.7.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-intelex>=2023.0.1->pycaret[full]) (2024.7.0)\n",
            "Requirement already satisfied: daal==2024.7.0 in /usr/local/lib/python3.10/dist-packages (from daal4py==2024.7.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (2024.7.0)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.10/dist-packages (from daal==2024.7.0->daal4py==2024.7.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (2021.13.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize>=0.9.0->pycaret[full]) (24.7.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap~=0.44.0->pycaret[full]) (0.0.7)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.2->pycaret[full]) (0.5.13)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.17.6->pycaret[full]) (0.14.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost>=1.1.0->pycaret[full]) (2.23.4)\n",
            "Requirement already satisfied: visions<0.7.7,>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (0.7.6)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.12.4)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.13.1)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.12)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.3.0)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.3)\n",
            "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.8.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling>=4.3.1->pycaret[full]) (1.7.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.6.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.8.2 in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.12.3)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.9.4)\n",
            "Requirement already satisfied: percy>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (2.0.2)\n",
            "Requirement already satisfied: selenium<=4.2.0,>=3.141.0 in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (3.141.0)\n",
            "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.70.16)\n",
            "Requirement already satisfied: dash-testing-stub>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->pycaret[full]) (1.3.5)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=3.50.2->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.8.2->dash[testing]; extra == \"full\"->pycaret[full]) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (1.17.1)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe,distributed]>=2023.5.0; extra == \"dask\"->fugue[dask]; extra == \"full\"->pycaret[full]) (1.1.10)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.10/dist-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[full]) (0.1.5)\n",
            "Requirement already satisfied: wtforms in /usr/local/lib/python3.10/dist-packages (from Flask-WTF>=1.1->explainerdashboard>=0.3.8->pycaret[full]) (3.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime<4.12 in /usr/local/lib/python3.10/dist-packages (from fugue-sql-antlr>=0.1.6->fugue~=0.8.0->pycaret[full]) (4.11.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.4)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (9.0.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=3.50.2->pycaret[full]) (1.0.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (6.1.12)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.4.4)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.7.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[full]) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[full]) (4.3.6)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.10/dist-packages (from jupyter-dash>=0.4.1->explainerdashboard>=0.3.8->pycaret[full]) (1.9.2)\n",
            "Requirement already satisfied: msgspec>=0.18.2 in /usr/local/lib/python3.10/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.18.6)\n",
            "Requirement already satisfied: multidict>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (6.1.0)\n",
            "Requirement already satisfied: polyfactory>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (2.17.0)\n",
            "Requirement already satisfied: rich-click in /usr/local/lib/python3.10/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.8.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.7->evidently~=0.4.16->pycaret[full]) (2024.9.11)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret[full]) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13->evidently~=0.4.16->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->pycaret[full]) (3.1.0)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.3->fugue~=0.8.0->pycaret[full]) (2.4.16)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.3->evidently~=0.4.16->pycaret[full]) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.9.0->evidently~=0.4.16->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.20.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.24.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.5.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (2.22)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (2.27.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.10/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.3->interpret>=0.2.7->pycaret[full]) (7.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13->evidently~=0.4.16->pycaret[full]) (0.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (0.48b0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (from polyfactory>=2.6.3->litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (29.0.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (4.9)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.2.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (21.2.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.24.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.0.0->pycaret[full]) (0.6.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.0)\n",
            "Dataset URL: https://www.kaggle.com/datasets/mbsoroush/google-dataset\n",
            "License(s): other\n",
            "Downloading google-dataset.zip to /content\n",
            "  0% 0.00/29.3k [00:00<?, ?B/s]\n",
            "100% 29.3k/29.3k [00:00<00:00, 34.6MB/s]\n",
            "Archive:  google-dataset.zip\n",
            "  inflating: GOOG.csv                \n"
          ]
        }
      ],
      "source": [
        "!pip install pycaret[full]\n",
        "import pycaret\n",
        "pycaret.__version__\n",
        "\n",
        "\n",
        "!kaggle datasets download -d mbsoroush/google-dataset\n",
        "\n",
        "!unzip google-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pycaret.time_series import TSForecastingExperiment\n"
      ],
      "metadata": {
        "id": "aQp98bdDRyEk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('GOOG.csv')\n",
        "from pycaret.time_series import *\n",
        "data = data[['adjClose']]\n",
        "data.index.freq = 'D'\n",
        "\n",
        "eda = TSForecastingExperiment()\n",
        "s = setup(data,fh=12,session_id=123,use_gpu = True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oosPi-QTSOvl",
        "outputId": "0f2161f2-688d-4a57-af9a-72d1afa2de95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cf1486f3580>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_6828a_row25_col1, #T_6828a_row33_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_6828a\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_6828a_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_6828a_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_6828a_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
              "      <td id=\"T_6828a_row0_col1\" class=\"data row0 col1\" >123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_6828a_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_6828a_row1_col1\" class=\"data row1 col1\" >adjClose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_6828a_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
              "      <td id=\"T_6828a_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_6828a_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
              "      <td id=\"T_6828a_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_6828a_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
              "      <td id=\"T_6828a_row4_col1\" class=\"data row4 col1\" >(1258, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_6828a_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_6828a_row5_col1\" class=\"data row5 col1\" >(1258, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_6828a_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_6828a_row6_col1\" class=\"data row6 col1\" >(1246, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_6828a_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_6828a_row7_col1\" class=\"data row7 col1\" >(12, 1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_6828a_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
              "      <td id=\"T_6828a_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_6828a_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_6828a_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_6828a_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
              "      <td id=\"T_6828a_row10_col1\" class=\"data row10 col1\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_6828a_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
              "      <td id=\"T_6828a_row11_col1\" class=\"data row11 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_6828a_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
              "      <td id=\"T_6828a_row12_col1\" class=\"data row12 col1\" >all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_6828a_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
              "      <td id=\"T_6828a_row13_col1\" class=\"data row13 col1\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_6828a_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
              "      <td id=\"T_6828a_row14_col1\" class=\"data row14 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_6828a_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
              "      <td id=\"T_6828a_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_6828a_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
              "      <td id=\"T_6828a_row16_col1\" class=\"data row16 col1\" >60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_6828a_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
              "      <td id=\"T_6828a_row17_col1\" class=\"data row17 col1\" >[7, 16, 9, 18, 25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_6828a_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
              "      <td id=\"T_6828a_row18_col1\" class=\"data row18 col1\" >[7, 16, 9, 18, 25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_6828a_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
              "      <td id=\"T_6828a_row19_col1\" class=\"data row19 col1\" >[7, 16, 18, 25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_6828a_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
              "      <td id=\"T_6828a_row20_col1\" class=\"data row20 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "      <td id=\"T_6828a_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
              "      <td id=\"T_6828a_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "      <td id=\"T_6828a_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
              "      <td id=\"T_6828a_row22_col1\" class=\"data row22 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "      <td id=\"T_6828a_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
              "      <td id=\"T_6828a_row23_col1\" class=\"data row23 col1\" >[7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "      <td id=\"T_6828a_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
              "      <td id=\"T_6828a_row24_col1\" class=\"data row24 col1\" >7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "      <td id=\"T_6828a_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
              "      <td id=\"T_6828a_row25_col1\" class=\"data row25 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "      <td id=\"T_6828a_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
              "      <td id=\"T_6828a_row26_col1\" class=\"data row26 col1\" >mul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "      <td id=\"T_6828a_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
              "      <td id=\"T_6828a_row27_col1\" class=\"data row27 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "      <td id=\"T_6828a_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
              "      <td id=\"T_6828a_row28_col1\" class=\"data row28 col1\" >No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "      <td id=\"T_6828a_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
              "      <td id=\"T_6828a_row29_col1\" class=\"data row29 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
              "      <td id=\"T_6828a_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
              "      <td id=\"T_6828a_row30_col1\" class=\"data row30 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
              "      <td id=\"T_6828a_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
              "      <td id=\"T_6828a_row31_col1\" class=\"data row31 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
              "      <td id=\"T_6828a_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_6828a_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
              "      <td id=\"T_6828a_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
              "      <td id=\"T_6828a_row33_col1\" class=\"data row33 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
              "      <td id=\"T_6828a_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_6828a_row34_col1\" class=\"data row34 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
              "      <td id=\"T_6828a_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_6828a_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6828a_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
              "      <td id=\"T_6828a_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
              "      <td id=\"T_6828a_row36_col1\" class=\"data row36 col1\" >7eeb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = compare_models()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896,
          "referenced_widgets": [
            "7c138cd69b56491093a1fd36c6fa3846",
            "aca3b75b4b674afb902b401f62a2477b",
            "906b17f02f6f49e49c6739bd5ee7df52",
            "f887fa706ca14b38b291e2978cc740fe",
            "1dc681a572184085a5172f1a7c7e2eed",
            "f0a72b0d06fb41949a8bb9e11f647ad6",
            "d374736e26f145b78e576a59ee9477cd",
            "870661043ab54de1a5bf36e2893fef54",
            "08f3e215ddc14ca9b87033f18ff13ec6",
            "60423e7a0a6e4afbb1c1bb66c5d98b96",
            "01c3ca9867914458a982a61b36e8f463"
          ]
        },
        "id": "baSw1U-rSo1w",
        "outputId": "11a28a2c-d5f8-4842-d9ac-6799d0df0ed3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cf14859dfc0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_db851 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_db851_row0_col0, #T_db851_row1_col0, #T_db851_row1_col1, #T_db851_row1_col2, #T_db851_row1_col3, #T_db851_row1_col4, #T_db851_row1_col5, #T_db851_row1_col6, #T_db851_row1_col7, #T_db851_row2_col0, #T_db851_row2_col1, #T_db851_row2_col2, #T_db851_row2_col3, #T_db851_row2_col4, #T_db851_row2_col5, #T_db851_row2_col6, #T_db851_row2_col7, #T_db851_row3_col0, #T_db851_row3_col1, #T_db851_row3_col2, #T_db851_row3_col3, #T_db851_row3_col4, #T_db851_row3_col5, #T_db851_row3_col6, #T_db851_row3_col7, #T_db851_row4_col0, #T_db851_row4_col1, #T_db851_row4_col2, #T_db851_row4_col3, #T_db851_row4_col4, #T_db851_row4_col5, #T_db851_row4_col6, #T_db851_row4_col7, #T_db851_row5_col0, #T_db851_row5_col1, #T_db851_row5_col2, #T_db851_row5_col3, #T_db851_row5_col4, #T_db851_row5_col5, #T_db851_row5_col6, #T_db851_row5_col7, #T_db851_row6_col0, #T_db851_row6_col1, #T_db851_row6_col2, #T_db851_row6_col3, #T_db851_row6_col4, #T_db851_row6_col5, #T_db851_row6_col6, #T_db851_row6_col7, #T_db851_row7_col0, #T_db851_row7_col1, #T_db851_row7_col2, #T_db851_row7_col3, #T_db851_row7_col4, #T_db851_row7_col5, #T_db851_row7_col6, #T_db851_row7_col7, #T_db851_row8_col0, #T_db851_row8_col1, #T_db851_row8_col2, #T_db851_row8_col3, #T_db851_row8_col4, #T_db851_row8_col5, #T_db851_row8_col6, #T_db851_row8_col7, #T_db851_row9_col0, #T_db851_row9_col1, #T_db851_row9_col2, #T_db851_row9_col3, #T_db851_row9_col4, #T_db851_row9_col5, #T_db851_row9_col6, #T_db851_row9_col7, #T_db851_row10_col0, #T_db851_row10_col1, #T_db851_row10_col2, #T_db851_row10_col3, #T_db851_row10_col4, #T_db851_row10_col5, #T_db851_row10_col6, #T_db851_row10_col7, #T_db851_row11_col0, #T_db851_row11_col1, #T_db851_row11_col2, #T_db851_row11_col3, #T_db851_row11_col4, #T_db851_row11_col5, #T_db851_row11_col6, #T_db851_row11_col7, #T_db851_row12_col0, #T_db851_row12_col1, #T_db851_row12_col2, #T_db851_row12_col3, #T_db851_row12_col4, #T_db851_row12_col5, #T_db851_row12_col6, #T_db851_row12_col7, #T_db851_row13_col0, #T_db851_row13_col1, #T_db851_row13_col2, #T_db851_row13_col3, #T_db851_row13_col4, #T_db851_row13_col5, #T_db851_row13_col6, #T_db851_row13_col7, #T_db851_row14_col0, #T_db851_row14_col1, #T_db851_row14_col2, #T_db851_row14_col3, #T_db851_row14_col4, #T_db851_row14_col5, #T_db851_row14_col6, #T_db851_row14_col7, #T_db851_row15_col0, #T_db851_row15_col1, #T_db851_row15_col2, #T_db851_row15_col3, #T_db851_row15_col4, #T_db851_row15_col5, #T_db851_row15_col6, #T_db851_row15_col7, #T_db851_row16_col0, #T_db851_row16_col1, #T_db851_row16_col2, #T_db851_row16_col3, #T_db851_row16_col4, #T_db851_row16_col5, #T_db851_row16_col6, #T_db851_row16_col7, #T_db851_row17_col0, #T_db851_row17_col1, #T_db851_row17_col2, #T_db851_row17_col3, #T_db851_row17_col4, #T_db851_row17_col5, #T_db851_row17_col6, #T_db851_row17_col7, #T_db851_row18_col0, #T_db851_row18_col1, #T_db851_row18_col2, #T_db851_row18_col3, #T_db851_row18_col4, #T_db851_row18_col5, #T_db851_row18_col6, #T_db851_row18_col7, #T_db851_row19_col0, #T_db851_row19_col1, #T_db851_row19_col2, #T_db851_row19_col3, #T_db851_row19_col4, #T_db851_row19_col5, #T_db851_row19_col6, #T_db851_row19_col7, #T_db851_row20_col0, #T_db851_row20_col1, #T_db851_row20_col2, #T_db851_row20_col3, #T_db851_row20_col4, #T_db851_row20_col5, #T_db851_row20_col6, #T_db851_row20_col7, #T_db851_row21_col0, #T_db851_row21_col1, #T_db851_row21_col2, #T_db851_row21_col3, #T_db851_row21_col4, #T_db851_row21_col5, #T_db851_row21_col6, #T_db851_row21_col7, #T_db851_row22_col0, #T_db851_row22_col1, #T_db851_row22_col2, #T_db851_row22_col3, #T_db851_row22_col4, #T_db851_row22_col5, #T_db851_row22_col6, #T_db851_row22_col7, #T_db851_row23_col0, #T_db851_row23_col1, #T_db851_row23_col2, #T_db851_row23_col3, #T_db851_row23_col4, #T_db851_row23_col5, #T_db851_row23_col6, #T_db851_row23_col7, #T_db851_row24_col0, #T_db851_row24_col1, #T_db851_row24_col2, #T_db851_row24_col3, #T_db851_row24_col4, #T_db851_row24_col5, #T_db851_row24_col6, #T_db851_row24_col7, #T_db851_row25_col0, #T_db851_row25_col1, #T_db851_row25_col2, #T_db851_row25_col3, #T_db851_row25_col4, #T_db851_row25_col5, #T_db851_row25_col6, #T_db851_row25_col7, #T_db851_row26_col0, #T_db851_row26_col1, #T_db851_row26_col2, #T_db851_row26_col3, #T_db851_row26_col4, #T_db851_row26_col5, #T_db851_row26_col6, #T_db851_row26_col7 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_db851_row0_col1, #T_db851_row0_col2, #T_db851_row0_col3, #T_db851_row0_col4, #T_db851_row0_col5, #T_db851_row0_col6, #T_db851_row0_col7 {\n",
              "  text-align: left;\n",
              "  background-color: yellow;\n",
              "}\n",
              "#T_db851_row0_col8, #T_db851_row1_col8, #T_db851_row2_col8, #T_db851_row3_col8, #T_db851_row4_col8, #T_db851_row5_col8, #T_db851_row6_col8, #T_db851_row7_col8, #T_db851_row8_col8, #T_db851_row9_col8, #T_db851_row10_col8, #T_db851_row11_col8, #T_db851_row12_col8, #T_db851_row13_col8, #T_db851_row14_col8, #T_db851_row15_col8, #T_db851_row16_col8, #T_db851_row17_col8, #T_db851_row18_col8, #T_db851_row19_col8, #T_db851_row20_col8, #T_db851_row21_col8, #T_db851_row22_col8, #T_db851_row23_col8, #T_db851_row24_col8, #T_db851_row26_col8 {\n",
              "  text-align: left;\n",
              "  background-color: lightgrey;\n",
              "}\n",
              "#T_db851_row25_col8 {\n",
              "  text-align: left;\n",
              "  background-color: yellow;\n",
              "  background-color: lightgrey;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_db851\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_db851_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_db851_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
              "      <th id=\"T_db851_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
              "      <th id=\"T_db851_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
              "      <th id=\"T_db851_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
              "      <th id=\"T_db851_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
              "      <th id=\"T_db851_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
              "      <th id=\"T_db851_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
              "      <th id=\"T_db851_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row0\" class=\"row_heading level0 row0\" >exp_smooth</th>\n",
              "      <td id=\"T_db851_row0_col0\" class=\"data row0 col0\" >Exponential Smoothing</td>\n",
              "      <td id=\"T_db851_row0_col1\" class=\"data row0 col1\" >1.5980</td>\n",
              "      <td id=\"T_db851_row0_col2\" class=\"data row0 col2\" >1.2264</td>\n",
              "      <td id=\"T_db851_row0_col3\" class=\"data row0 col3\" >58.7377</td>\n",
              "      <td id=\"T_db851_row0_col4\" class=\"data row0 col4\" >64.6133</td>\n",
              "      <td id=\"T_db851_row0_col5\" class=\"data row0 col5\" >0.0253</td>\n",
              "      <td id=\"T_db851_row0_col6\" class=\"data row0 col6\" >0.0248</td>\n",
              "      <td id=\"T_db851_row0_col7\" class=\"data row0 col7\" >-1.9479</td>\n",
              "      <td id=\"T_db851_row0_col8\" class=\"data row0 col8\" >0.3500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row1\" class=\"row_heading level0 row1\" >auto_arima</th>\n",
              "      <td id=\"T_db851_row1_col0\" class=\"data row1 col0\" >Auto ARIMA</td>\n",
              "      <td id=\"T_db851_row1_col1\" class=\"data row1 col1\" >1.6243</td>\n",
              "      <td id=\"T_db851_row1_col2\" class=\"data row1 col2\" >1.2885</td>\n",
              "      <td id=\"T_db851_row1_col3\" class=\"data row1 col3\" >59.4883</td>\n",
              "      <td id=\"T_db851_row1_col4\" class=\"data row1 col4\" >67.6286</td>\n",
              "      <td id=\"T_db851_row1_col5\" class=\"data row1 col5\" >0.0256</td>\n",
              "      <td id=\"T_db851_row1_col6\" class=\"data row1 col6\" >0.0255</td>\n",
              "      <td id=\"T_db851_row1_col7\" class=\"data row1 col7\" >-1.9504</td>\n",
              "      <td id=\"T_db851_row1_col8\" class=\"data row1 col8\" >53.3300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row2\" class=\"row_heading level0 row2\" >ets</th>\n",
              "      <td id=\"T_db851_row2_col0\" class=\"data row2 col0\" >ETS</td>\n",
              "      <td id=\"T_db851_row2_col1\" class=\"data row2 col1\" >1.6684</td>\n",
              "      <td id=\"T_db851_row2_col2\" class=\"data row2 col2\" >1.3048</td>\n",
              "      <td id=\"T_db851_row2_col3\" class=\"data row2 col3\" >61.1670</td>\n",
              "      <td id=\"T_db851_row2_col4\" class=\"data row2 col4\" >68.5402</td>\n",
              "      <td id=\"T_db851_row2_col5\" class=\"data row2 col5\" >0.0263</td>\n",
              "      <td id=\"T_db851_row2_col6\" class=\"data row2 col6\" >0.0261</td>\n",
              "      <td id=\"T_db851_row2_col7\" class=\"data row2 col7\" >-2.0182</td>\n",
              "      <td id=\"T_db851_row2_col8\" class=\"data row2 col8\" >0.4400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row3\" class=\"row_heading level0 row3\" >naive</th>\n",
              "      <td id=\"T_db851_row3_col0\" class=\"data row3 col0\" >Naive Forecaster</td>\n",
              "      <td id=\"T_db851_row3_col1\" class=\"data row3 col1\" >1.7764</td>\n",
              "      <td id=\"T_db851_row3_col2\" class=\"data row3 col2\" >1.4111</td>\n",
              "      <td id=\"T_db851_row3_col3\" class=\"data row3 col3\" >64.9650</td>\n",
              "      <td id=\"T_db851_row3_col4\" class=\"data row3 col4\" >73.9213</td>\n",
              "      <td id=\"T_db851_row3_col5\" class=\"data row3 col5\" >0.0279</td>\n",
              "      <td id=\"T_db851_row3_col6\" class=\"data row3 col6\" >0.0280</td>\n",
              "      <td id=\"T_db851_row3_col7\" class=\"data row3 col7\" >-2.8592</td>\n",
              "      <td id=\"T_db851_row3_col8\" class=\"data row3 col8\" >0.2733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row4\" class=\"row_heading level0 row4\" >theta</th>\n",
              "      <td id=\"T_db851_row4_col0\" class=\"data row4 col0\" >Theta Forecaster</td>\n",
              "      <td id=\"T_db851_row4_col1\" class=\"data row4 col1\" >1.8519</td>\n",
              "      <td id=\"T_db851_row4_col2\" class=\"data row4 col2\" >1.4639</td>\n",
              "      <td id=\"T_db851_row4_col3\" class=\"data row4 col3\" >67.6878</td>\n",
              "      <td id=\"T_db851_row4_col4\" class=\"data row4 col4\" >76.6427</td>\n",
              "      <td id=\"T_db851_row4_col5\" class=\"data row4 col5\" >0.0291</td>\n",
              "      <td id=\"T_db851_row4_col6\" class=\"data row4 col6\" >0.0292</td>\n",
              "      <td id=\"T_db851_row4_col7\" class=\"data row4 col7\" >-3.3238</td>\n",
              "      <td id=\"T_db851_row4_col8\" class=\"data row4 col8\" >0.1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row5\" class=\"row_heading level0 row5\" >omp_cds_dt</th>\n",
              "      <td id=\"T_db851_row5_col0\" class=\"data row5 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row5_col1\" class=\"data row5 col1\" >1.9980</td>\n",
              "      <td id=\"T_db851_row5_col2\" class=\"data row5 col2\" >1.5784</td>\n",
              "      <td id=\"T_db851_row5_col3\" class=\"data row5 col3\" >72.9903</td>\n",
              "      <td id=\"T_db851_row5_col4\" class=\"data row5 col4\" >82.5726</td>\n",
              "      <td id=\"T_db851_row5_col5\" class=\"data row5 col5\" >0.0314</td>\n",
              "      <td id=\"T_db851_row5_col6\" class=\"data row5 col6\" >0.0316</td>\n",
              "      <td id=\"T_db851_row5_col7\" class=\"data row5 col7\" >-4.2800</td>\n",
              "      <td id=\"T_db851_row5_col8\" class=\"data row5 col8\" >0.5467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row6\" class=\"row_heading level0 row6\" >arima</th>\n",
              "      <td id=\"T_db851_row6_col0\" class=\"data row6 col0\" >ARIMA</td>\n",
              "      <td id=\"T_db851_row6_col1\" class=\"data row6 col1\" >2.0359</td>\n",
              "      <td id=\"T_db851_row6_col2\" class=\"data row6 col2\" >1.5822</td>\n",
              "      <td id=\"T_db851_row6_col3\" class=\"data row6 col3\" >74.2807</td>\n",
              "      <td id=\"T_db851_row6_col4\" class=\"data row6 col4\" >82.6044</td>\n",
              "      <td id=\"T_db851_row6_col5\" class=\"data row6 col5\" >0.0321</td>\n",
              "      <td id=\"T_db851_row6_col6\" class=\"data row6 col6\" >0.0321</td>\n",
              "      <td id=\"T_db851_row6_col7\" class=\"data row6 col7\" >-5.5669</td>\n",
              "      <td id=\"T_db851_row6_col8\" class=\"data row6 col8\" >0.5933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row7\" class=\"row_heading level0 row7\" >huber_cds_dt</th>\n",
              "      <td id=\"T_db851_row7_col0\" class=\"data row7 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row7_col1\" class=\"data row7 col1\" >2.0523</td>\n",
              "      <td id=\"T_db851_row7_col2\" class=\"data row7 col2\" >1.6123</td>\n",
              "      <td id=\"T_db851_row7_col3\" class=\"data row7 col3\" >74.9281</td>\n",
              "      <td id=\"T_db851_row7_col4\" class=\"data row7 col4\" >84.2839</td>\n",
              "      <td id=\"T_db851_row7_col5\" class=\"data row7 col5\" >0.0323</td>\n",
              "      <td id=\"T_db851_row7_col6\" class=\"data row7 col6\" >0.0324</td>\n",
              "      <td id=\"T_db851_row7_col7\" class=\"data row7 col7\" >-4.8467</td>\n",
              "      <td id=\"T_db851_row7_col8\" class=\"data row7 col8\" >0.5967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row8\" class=\"row_heading level0 row8\" >lasso_cds_dt</th>\n",
              "      <td id=\"T_db851_row8_col0\" class=\"data row8 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row8_col1\" class=\"data row8 col1\" >2.1029</td>\n",
              "      <td id=\"T_db851_row8_col2\" class=\"data row8 col2\" >1.6334</td>\n",
              "      <td id=\"T_db851_row8_col3\" class=\"data row8 col3\" >76.8296</td>\n",
              "      <td id=\"T_db851_row8_col4\" class=\"data row8 col4\" >85.4410</td>\n",
              "      <td id=\"T_db851_row8_col5\" class=\"data row8 col5\" >0.0331</td>\n",
              "      <td id=\"T_db851_row8_col6\" class=\"data row8 col6\" >0.0331</td>\n",
              "      <td id=\"T_db851_row8_col7\" class=\"data row8 col7\" >-4.8249</td>\n",
              "      <td id=\"T_db851_row8_col8\" class=\"data row8 col8\" >0.5800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row9\" class=\"row_heading level0 row9\" >llar_cds_dt</th>\n",
              "      <td id=\"T_db851_row9_col0\" class=\"data row9 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row9_col1\" class=\"data row9 col1\" >2.1029</td>\n",
              "      <td id=\"T_db851_row9_col2\" class=\"data row9 col2\" >1.6333</td>\n",
              "      <td id=\"T_db851_row9_col3\" class=\"data row9 col3\" >76.8318</td>\n",
              "      <td id=\"T_db851_row9_col4\" class=\"data row9 col4\" >85.4382</td>\n",
              "      <td id=\"T_db851_row9_col5\" class=\"data row9 col5\" >0.0331</td>\n",
              "      <td id=\"T_db851_row9_col6\" class=\"data row9 col6\" >0.0331</td>\n",
              "      <td id=\"T_db851_row9_col7\" class=\"data row9 col7\" >-4.8246</td>\n",
              "      <td id=\"T_db851_row9_col8\" class=\"data row9 col8\" >0.8433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row10\" class=\"row_heading level0 row10\" >ridge_cds_dt</th>\n",
              "      <td id=\"T_db851_row10_col0\" class=\"data row10 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row10_col1\" class=\"data row10 col1\" >2.1040</td>\n",
              "      <td id=\"T_db851_row10_col2\" class=\"data row10 col2\" >1.6342</td>\n",
              "      <td id=\"T_db851_row10_col3\" class=\"data row10 col3\" >76.8742</td>\n",
              "      <td id=\"T_db851_row10_col4\" class=\"data row10 col4\" >85.4871</td>\n",
              "      <td id=\"T_db851_row10_col5\" class=\"data row10 col5\" >0.0331</td>\n",
              "      <td id=\"T_db851_row10_col6\" class=\"data row10 col6\" >0.0332</td>\n",
              "      <td id=\"T_db851_row10_col7\" class=\"data row10 col7\" >-4.8206</td>\n",
              "      <td id=\"T_db851_row10_col8\" class=\"data row10 col8\" >0.6233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row11\" class=\"row_heading level0 row11\" >lr_cds_dt</th>\n",
              "      <td id=\"T_db851_row11_col0\" class=\"data row11 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row11_col1\" class=\"data row11 col1\" >2.1040</td>\n",
              "      <td id=\"T_db851_row11_col2\" class=\"data row11 col2\" >1.6342</td>\n",
              "      <td id=\"T_db851_row11_col3\" class=\"data row11 col3\" >76.8742</td>\n",
              "      <td id=\"T_db851_row11_col4\" class=\"data row11 col4\" >85.4871</td>\n",
              "      <td id=\"T_db851_row11_col5\" class=\"data row11 col5\" >0.0331</td>\n",
              "      <td id=\"T_db851_row11_col6\" class=\"data row11 col6\" >0.0332</td>\n",
              "      <td id=\"T_db851_row11_col7\" class=\"data row11 col7\" >-4.8206</td>\n",
              "      <td id=\"T_db851_row11_col8\" class=\"data row11 col8\" >0.5867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row12\" class=\"row_heading level0 row12\" >en_cds_dt</th>\n",
              "      <td id=\"T_db851_row12_col0\" class=\"data row12 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row12_col1\" class=\"data row12 col1\" >2.1048</td>\n",
              "      <td id=\"T_db851_row12_col2\" class=\"data row12 col2\" >1.6346</td>\n",
              "      <td id=\"T_db851_row12_col3\" class=\"data row12 col3\" >76.8987</td>\n",
              "      <td id=\"T_db851_row12_col4\" class=\"data row12 col4\" >85.5060</td>\n",
              "      <td id=\"T_db851_row12_col5\" class=\"data row12 col5\" >0.0331</td>\n",
              "      <td id=\"T_db851_row12_col6\" class=\"data row12 col6\" >0.0332</td>\n",
              "      <td id=\"T_db851_row12_col7\" class=\"data row12 col7\" >-4.8327</td>\n",
              "      <td id=\"T_db851_row12_col8\" class=\"data row12 col8\" >0.5800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row13\" class=\"row_heading level0 row13\" >br_cds_dt</th>\n",
              "      <td id=\"T_db851_row13_col0\" class=\"data row13 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row13_col1\" class=\"data row13 col1\" >2.1065</td>\n",
              "      <td id=\"T_db851_row13_col2\" class=\"data row13 col2\" >1.6358</td>\n",
              "      <td id=\"T_db851_row13_col3\" class=\"data row13 col3\" >76.9616</td>\n",
              "      <td id=\"T_db851_row13_col4\" class=\"data row13 col4\" >85.5640</td>\n",
              "      <td id=\"T_db851_row13_col5\" class=\"data row13 col5\" >0.0332</td>\n",
              "      <td id=\"T_db851_row13_col6\" class=\"data row13 col6\" >0.0332</td>\n",
              "      <td id=\"T_db851_row13_col7\" class=\"data row13 col7\" >-4.8551</td>\n",
              "      <td id=\"T_db851_row13_col8\" class=\"data row13 col8\" >0.6533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row14\" class=\"row_heading level0 row14\" >ada_cds_dt</th>\n",
              "      <td id=\"T_db851_row14_col0\" class=\"data row14 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row14_col1\" class=\"data row14 col1\" >2.4223</td>\n",
              "      <td id=\"T_db851_row14_col2\" class=\"data row14 col2\" >1.8165</td>\n",
              "      <td id=\"T_db851_row14_col3\" class=\"data row14 col3\" >88.1709</td>\n",
              "      <td id=\"T_db851_row14_col4\" class=\"data row14 col4\" >94.6264</td>\n",
              "      <td id=\"T_db851_row14_col5\" class=\"data row14 col5\" >0.0380</td>\n",
              "      <td id=\"T_db851_row14_col6\" class=\"data row14 col6\" >0.0387</td>\n",
              "      <td id=\"T_db851_row14_col7\" class=\"data row14 col7\" >-8.9036</td>\n",
              "      <td id=\"T_db851_row14_col8\" class=\"data row14 col8\" >0.8800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row15\" class=\"row_heading level0 row15\" >rf_cds_dt</th>\n",
              "      <td id=\"T_db851_row15_col0\" class=\"data row15 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row15_col1\" class=\"data row15 col1\" >2.5095</td>\n",
              "      <td id=\"T_db851_row15_col2\" class=\"data row15 col2\" >1.9167</td>\n",
              "      <td id=\"T_db851_row15_col3\" class=\"data row15 col3\" >91.1906</td>\n",
              "      <td id=\"T_db851_row15_col4\" class=\"data row15 col4\" >99.5933</td>\n",
              "      <td id=\"T_db851_row15_col5\" class=\"data row15 col5\" >0.0395</td>\n",
              "      <td id=\"T_db851_row15_col6\" class=\"data row15 col6\" >0.0401</td>\n",
              "      <td id=\"T_db851_row15_col7\" class=\"data row15 col7\" >-13.2006</td>\n",
              "      <td id=\"T_db851_row15_col8\" class=\"data row15 col8\" >1.9933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row16\" class=\"row_heading level0 row16\" >gbr_cds_dt</th>\n",
              "      <td id=\"T_db851_row16_col0\" class=\"data row16 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row16_col1\" class=\"data row16 col1\" >2.6839</td>\n",
              "      <td id=\"T_db851_row16_col2\" class=\"data row16 col2\" >2.0810</td>\n",
              "      <td id=\"T_db851_row16_col3\" class=\"data row16 col3\" >97.5175</td>\n",
              "      <td id=\"T_db851_row16_col4\" class=\"data row16 col4\" >108.0882</td>\n",
              "      <td id=\"T_db851_row16_col5\" class=\"data row16 col5\" >0.0422</td>\n",
              "      <td id=\"T_db851_row16_col6\" class=\"data row16 col6\" >0.0430</td>\n",
              "      <td id=\"T_db851_row16_col7\" class=\"data row16 col7\" >-16.3066</td>\n",
              "      <td id=\"T_db851_row16_col8\" class=\"data row16 col8\" >1.3867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row17\" class=\"row_heading level0 row17\" >et_cds_dt</th>\n",
              "      <td id=\"T_db851_row17_col0\" class=\"data row17 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row17_col1\" class=\"data row17 col1\" >2.6903</td>\n",
              "      <td id=\"T_db851_row17_col2\" class=\"data row17 col2\" >2.0647</td>\n",
              "      <td id=\"T_db851_row17_col3\" class=\"data row17 col3\" >97.6567</td>\n",
              "      <td id=\"T_db851_row17_col4\" class=\"data row17 col4\" >107.1099</td>\n",
              "      <td id=\"T_db851_row17_col5\" class=\"data row17 col5\" >0.0423</td>\n",
              "      <td id=\"T_db851_row17_col6\" class=\"data row17 col6\" >0.0432</td>\n",
              "      <td id=\"T_db851_row17_col7\" class=\"data row17 col7\" >-17.9929</td>\n",
              "      <td id=\"T_db851_row17_col8\" class=\"data row17 col8\" >1.2600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row18\" class=\"row_heading level0 row18\" >stlf</th>\n",
              "      <td id=\"T_db851_row18_col0\" class=\"data row18 col0\" >STLF</td>\n",
              "      <td id=\"T_db851_row18_col1\" class=\"data row18 col1\" >2.6923</td>\n",
              "      <td id=\"T_db851_row18_col2\" class=\"data row18 col2\" >2.0732</td>\n",
              "      <td id=\"T_db851_row18_col3\" class=\"data row18 col3\" >97.8692</td>\n",
              "      <td id=\"T_db851_row18_col4\" class=\"data row18 col4\" >107.7694</td>\n",
              "      <td id=\"T_db851_row18_col5\" class=\"data row18 col5\" >0.0425</td>\n",
              "      <td id=\"T_db851_row18_col6\" class=\"data row18 col6\" >0.0430</td>\n",
              "      <td id=\"T_db851_row18_col7\" class=\"data row18 col7\" >-15.4777</td>\n",
              "      <td id=\"T_db851_row18_col8\" class=\"data row18 col8\" >0.1667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row19\" class=\"row_heading level0 row19\" >lightgbm_cds_dt</th>\n",
              "      <td id=\"T_db851_row19_col0\" class=\"data row19 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row19_col1\" class=\"data row19 col1\" >2.7620</td>\n",
              "      <td id=\"T_db851_row19_col2\" class=\"data row19 col2\" >2.0618</td>\n",
              "      <td id=\"T_db851_row19_col3\" class=\"data row19 col3\" >100.3107</td>\n",
              "      <td id=\"T_db851_row19_col4\" class=\"data row19 col4\" >107.1015</td>\n",
              "      <td id=\"T_db851_row19_col5\" class=\"data row19 col5\" >0.0433</td>\n",
              "      <td id=\"T_db851_row19_col6\" class=\"data row19 col6\" >0.0444</td>\n",
              "      <td id=\"T_db851_row19_col7\" class=\"data row19 col7\" >-15.3946</td>\n",
              "      <td id=\"T_db851_row19_col8\" class=\"data row19 col8\" >0.7533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row20\" class=\"row_heading level0 row20\" >xgboost_cds_dt</th>\n",
              "      <td id=\"T_db851_row20_col0\" class=\"data row20 col0\" >Extreme Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row20_col1\" class=\"data row20 col1\" >2.7975</td>\n",
              "      <td id=\"T_db851_row20_col2\" class=\"data row20 col2\" >2.1343</td>\n",
              "      <td id=\"T_db851_row20_col3\" class=\"data row20 col3\" >101.5527</td>\n",
              "      <td id=\"T_db851_row20_col4\" class=\"data row20 col4\" >110.7489</td>\n",
              "      <td id=\"T_db851_row20_col5\" class=\"data row20 col5\" >0.0440</td>\n",
              "      <td id=\"T_db851_row20_col6\" class=\"data row20 col6\" >0.0450</td>\n",
              "      <td id=\"T_db851_row20_col7\" class=\"data row20 col7\" >-18.8807</td>\n",
              "      <td id=\"T_db851_row20_col8\" class=\"data row20 col8\" >0.9867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row21\" class=\"row_heading level0 row21\" >dt_cds_dt</th>\n",
              "      <td id=\"T_db851_row21_col0\" class=\"data row21 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row21_col1\" class=\"data row21 col1\" >2.8316</td>\n",
              "      <td id=\"T_db851_row21_col2\" class=\"data row21 col2\" >2.1913</td>\n",
              "      <td id=\"T_db851_row21_col3\" class=\"data row21 col3\" >102.7152</td>\n",
              "      <td id=\"T_db851_row21_col4\" class=\"data row21 col4\" >113.5744</td>\n",
              "      <td id=\"T_db851_row21_col5\" class=\"data row21 col5\" >0.0445</td>\n",
              "      <td id=\"T_db851_row21_col6\" class=\"data row21 col6\" >0.0457</td>\n",
              "      <td id=\"T_db851_row21_col7\" class=\"data row21 col7\" >-22.0236</td>\n",
              "      <td id=\"T_db851_row21_col8\" class=\"data row21 col8\" >0.6867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row22\" class=\"row_heading level0 row22\" >knn_cds_dt</th>\n",
              "      <td id=\"T_db851_row22_col0\" class=\"data row22 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
              "      <td id=\"T_db851_row22_col1\" class=\"data row22 col1\" >2.8712</td>\n",
              "      <td id=\"T_db851_row22_col2\" class=\"data row22 col2\" >2.1560</td>\n",
              "      <td id=\"T_db851_row22_col3\" class=\"data row22 col3\" >104.1033</td>\n",
              "      <td id=\"T_db851_row22_col4\" class=\"data row22 col4\" >111.7088</td>\n",
              "      <td id=\"T_db851_row22_col5\" class=\"data row22 col5\" >0.0452</td>\n",
              "      <td id=\"T_db851_row22_col6\" class=\"data row22 col6\" >0.0464</td>\n",
              "      <td id=\"T_db851_row22_col7\" class=\"data row22 col7\" >-22.0091</td>\n",
              "      <td id=\"T_db851_row22_col8\" class=\"data row22 col8\" >0.7400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row23\" class=\"row_heading level0 row23\" >snaive</th>\n",
              "      <td id=\"T_db851_row23_col0\" class=\"data row23 col0\" >Seasonal Naive Forecaster</td>\n",
              "      <td id=\"T_db851_row23_col1\" class=\"data row23 col1\" >3.2651</td>\n",
              "      <td id=\"T_db851_row23_col2\" class=\"data row23 col2\" >2.4619</td>\n",
              "      <td id=\"T_db851_row23_col3\" class=\"data row23 col3\" >118.4783</td>\n",
              "      <td id=\"T_db851_row23_col4\" class=\"data row23 col4\" >127.6230</td>\n",
              "      <td id=\"T_db851_row23_col5\" class=\"data row23 col5\" >0.0514</td>\n",
              "      <td id=\"T_db851_row23_col6\" class=\"data row23 col6\" >0.0529</td>\n",
              "      <td id=\"T_db851_row23_col7\" class=\"data row23 col7\" >-27.7010</td>\n",
              "      <td id=\"T_db851_row23_col8\" class=\"data row23 col8\" >0.1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row24\" class=\"row_heading level0 row24\" >croston</th>\n",
              "      <td id=\"T_db851_row24_col0\" class=\"data row24 col0\" >Croston</td>\n",
              "      <td id=\"T_db851_row24_col1\" class=\"data row24 col1\" >3.3894</td>\n",
              "      <td id=\"T_db851_row24_col2\" class=\"data row24 col2\" >2.4934</td>\n",
              "      <td id=\"T_db851_row24_col3\" class=\"data row24 col3\" >122.9930</td>\n",
              "      <td id=\"T_db851_row24_col4\" class=\"data row24 col4\" >129.3682</td>\n",
              "      <td id=\"T_db851_row24_col5\" class=\"data row24 col5\" >0.0531</td>\n",
              "      <td id=\"T_db851_row24_col6\" class=\"data row24 col6\" >0.0550</td>\n",
              "      <td id=\"T_db851_row24_col7\" class=\"data row24 col7\" >-25.6461</td>\n",
              "      <td id=\"T_db851_row24_col8\" class=\"data row24 col8\" >0.0633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row25\" class=\"row_heading level0 row25\" >polytrend</th>\n",
              "      <td id=\"T_db851_row25_col0\" class=\"data row25 col0\" >Polynomial Trend Forecaster</td>\n",
              "      <td id=\"T_db851_row25_col1\" class=\"data row25 col1\" >16.8016</td>\n",
              "      <td id=\"T_db851_row25_col2\" class=\"data row25 col2\" >11.7633</td>\n",
              "      <td id=\"T_db851_row25_col3\" class=\"data row25 col3\" >613.1364</td>\n",
              "      <td id=\"T_db851_row25_col4\" class=\"data row25 col4\" >614.3622</td>\n",
              "      <td id=\"T_db851_row25_col5\" class=\"data row25 col5\" >0.2640</td>\n",
              "      <td id=\"T_db851_row25_col6\" class=\"data row25 col6\" >0.3043</td>\n",
              "      <td id=\"T_db851_row25_col7\" class=\"data row25 col7\" >-333.4664</td>\n",
              "      <td id=\"T_db851_row25_col8\" class=\"data row25 col8\" >0.0400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_db851_level0_row26\" class=\"row_heading level0 row26\" >grand_means</th>\n",
              "      <td id=\"T_db851_row26_col0\" class=\"data row26 col0\" >Grand Means Forecaster</td>\n",
              "      <td id=\"T_db851_row26_col1\" class=\"data row26 col1\" >31.1780</td>\n",
              "      <td id=\"T_db851_row26_col2\" class=\"data row26 col2\" >21.7987</td>\n",
              "      <td id=\"T_db851_row26_col3\" class=\"data row26 col3\" >1137.9626</td>\n",
              "      <td id=\"T_db851_row26_col4\" class=\"data row26 col4\" >1138.6864</td>\n",
              "      <td id=\"T_db851_row26_col5\" class=\"data row26 col5\" >0.4902</td>\n",
              "      <td id=\"T_db851_row26_col6\" class=\"data row26 col6\" >0.6495</td>\n",
              "      <td id=\"T_db851_row26_col7\" class=\"data row26 col7\" >-1134.1102</td>\n",
              "      <td id=\"T_db851_row26_col8\" class=\"data row26 col8\" >0.0667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing:   0%|          | 0/121 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c138cd69b56491093a1fd36c6fa3846"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(best_model, plot = 'forecast')\n",
        "plot_model(best_model, plot = 'forecast', data_kwargs = {'fh' : 36})\n",
        "plot_model(best_model, plot = 'residuals')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m4sLN6cXSwej",
        "outputId": "368b43b5-584d-4aae-f900-d1198b8759f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"bbac7dbc-d8d9-44e8-a1fc-b344b53d7b66\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bbac7dbc-d8d9-44e8-a1fc-b344b53d7b66\")) {                    Plotly.newPlot(                        \"bbac7dbc-d8d9-44e8-a1fc-b344b53d7b66\",                        [{\"line\":{\"color\":\"rgb(31, 119, 180)\",\"width\":2},\"marker\":{\"color\":\"rgb(31, 119, 180)\",\"size\":5},\"mode\":\"lines+markers\",\"name\":\"adjClose\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257],\"y\":[718.27,718.92,710.36,691.72,693.71,695.94,697.46,701.87,675.22,668.26,680.04,684.11,692.1,699.21,694.49,697.77,695.36,705.63,715.09,720.64,716.98,720.95,719.85,733.78,736.96,741.19,738.63,742.74,739.77,738.42,741.77,745.91,768.79,772.88,771.07,773.18,771.61,782.22,781.76,784.26,784.68,784.85,783.22,782.44,777.14,779.91,777.5,775.42,772.15,772.08,769.64,769.41,769.54,772.15,769.09,767.05,768.78,771.46,780.08,780.35,775.32,759.66,769.02,759.69,762.49,771.76,768.88,765.7,771.41,776.22,787.21,786.9,774.21,783.01,781.56,775.01,777.29,772.56,776.43,776.47,776.86,775.08,785.94,783.07,786.14,778.19,778.53,779.96,795.26,801.56,796.97,799.37,813.11,807.67,799.07,795.35,795.37,784.54,783.61,768.7,762.13,762.02,782.52,790.51,785.31,762.56,754.02,736.08,758.49,764.48,771.23,760.54,769.2,768.27,760.99,761.68,768.24,770.84,758.04,747.92,750.5,762.52,759.11,771.19,776.42,789.29,789.27,796.1,797.07,797.85,790.8,794.2,796.42,794.56,791.26,789.91,791.55,785.05,782.79,771.82,786.14,786.9,794.02,806.15,806.65,804.79,807.91,806.36,807.88,804.61,806.07,802.175,805.02,819.31,823.87,835.67,832.15,823.31,802.32,796.79,795.695,798.53,801.49,801.34,806.97,808.38,809.56,813.67,819.24,820.45,818.98,824.16,828.07,831.66,830.76,831.33,828.64,829.28,823.21,835.24,830.63,829.08,827.78,831.91,835.37,838.68,843.25,845.54,845.62,847.2,848.78,852.12,848.4,830.46,829.59,817.58,814.43,819.51,820.92,831.41,831.5,829.56,838.55,834.57,831.41,827.88,824.67,824.73,823.35,824.32,823.56,837.17,836.82,838.21,841.65,843.19,862.76,872.3,871.73,874.25,905.96,912.57,916.44,927.04,931.66,927.13,934.3,932.17,928.78,930.6,932.22,937.08,943.0,919.62,930.24,934.01,941.86,948.82,954.96,969.54,971.47,975.88,964.86,966.95,975.6,983.68,976.57,980.94,983.41,949.83,942.9,953.4,950.76,942.31,939.78,957.37,950.63,959.45,957.09,965.59,952.27,927.33,940.49,917.79,908.73,898.7,911.71,906.69,918.59,928.8,930.09,943.83,947.16,955.99,953.42,965.4,970.89,968.15,972.92,980.34,950.7,947.8,934.09,941.53,930.5,930.83,930.39,923.65,927.96,929.36,926.79,922.9,907.24,914.39,922.67,922.22,926.96,910.98,910.67,906.66,924.69,927.0,921.28,915.89,913.81,921.29,929.57,939.33,937.34,928.45,927.81,935.95,926.5,929.08,932.07,935.09,925.11,920.29,915.0,921.81,931.58,932.45,928.53,920.97,924.86,944.49,949.5,959.11,953.27,957.79,951.68,969.96,978.89,977.0,972.6,989.25,987.83,989.68,992.0,992.18,992.81,984.45,988.2,968.45,970.54,973.33,972.56,1019.27,1017.11,1016.64,1025.5,1025.58,1032.48,1025.9,1033.33,1039.85,1031.26,1028.07,1025.75,1026.0,1020.91,1032.5,1019.09,1018.38,1034.49,1035.96,1040.61,1054.21,1047.41,1021.66,1021.41,1010.17,998.68,1005.15,1018.38,1030.93,1037.05,1041.1,1040.48,1040.61,1049.15,1064.19,1077.14,1070.68,1064.95,1063.63,1060.12,1056.74,1049.37,1048.14,1046.4,1065.0,1082.48,1086.4,1102.23,1106.94,1106.26,1102.61,1105.52,1122.26,1121.76,1131.98,1129.79,1137.51,1155.81,1169.97,1164.24,1170.37,1175.84,1175.58,1163.69,1169.94,1167.7,1111.9,1055.8,1080.6,1048.58,1001.52,1037.78,1051.94,1052.1,1069.7,1089.52,1094.8,1102.46,1111.34,1106.63,1126.79,1143.75,1118.29,1104.73,1069.52,1078.92,1090.93,1095.06,1109.64,1126.0,1160.04,1164.5,1138.17,1149.49,1149.58,1135.73,1099.82,1097.71,1090.88,1049.08,1021.57,1053.21,1005.1,1004.56,1031.79,1006.47,1013.41,1025.14,1027.81,1007.04,1015.45,1031.64,1019.97,1032.51,1029.27,1037.98,1074.16,1072.08,1087.7,1072.96,1067.45,1019.98,1021.18,1040.04,1030.05,1017.33,1037.31,1024.38,1023.72,1048.21,1054.79,1053.91,1082.76,1097.57,1098.26,1100.2,1079.23,1081.77,1078.59,1066.36,1079.58,1069.73,1079.69,1079.24,1075.66,1060.32,1067.8,1084.99,1119.5,1139.29,1139.66,1136.88,1123.86,1120.87,1129.99,1139.32,1134.79,1152.12,1152.26,1173.46,1168.06,1169.84,1157.66,1155.48,1124.81,1118.46,1103.98,1114.22,1115.65,1127.46,1102.89,1124.27,1140.17,1154.05,1152.84,1153.9,1183.48,1188.82,1183.86,1198.8,1195.88,1186.96,1184.91,1205.5,1248.08,1263.7,1268.33,1238.5,1219.74,1217.26,1220.01,1226.15,1223.71,1224.77,1242.22,1245.61,1249.1,1237.61,1235.01,1242.1,1214.38,1206.49,1200.96,1207.77,1201.62,1207.33,1205.38,1220.65,1241.82,1231.15,1249.3,1239.12,1218.19,1197.0,1186.48,1171.44,1164.83,1164.64,1177.36,1162.82,1175.33,1172.53,1156.05,1161.22,1171.09,1186.87,1166.09,1173.37,1184.65,1180.49,1194.64,1193.47,1195.31,1200.11,1202.95,1168.19,1157.35,1148.97,1138.82,1081.22,1079.32,1110.08,1092.25,1121.28,1115.69,1087.97,1096.46,1101.16,1103.69,1050.71,1095.57,1071.47,1020.08,1036.21,1076.77,1070.0,1057.79,1040.09,1055.81,1093.39,1082.4,1066.15,1038.63,1036.05,1043.66,1064.71,1061.49,1020.0,1025.76,1037.61,1023.88,1048.62,1044.41,1086.23,1088.3,1094.43,1106.43,1050.82,1068.73,1036.58,1039.55,1051.75,1063.68,1061.9,1042.1,1016.53,1028.71,1023.01,1009.41,979.54,976.22,1039.46,1043.88,1037.08,1035.61,1045.85,1016.06,1070.71,1068.39,1076.28,1074.66,1070.33,1057.19,1044.69,1077.15,1080.97,1089.9,1098.26,1070.52,1075.57,1073.9,1090.99,1070.08,1060.62,1089.06,1116.37,1110.75,1132.8,1145.99,1115.23,1098.71,1095.06,1095.01,1121.37,1120.16,1121.67,1113.65,1118.56,1113.8,1096.97,1110.37,1109.4,1115.13,1116.05,1119.92,1140.99,1147.8,1162.03,1157.86,1143.3,1142.32,1175.76,1193.2,1193.32,1185.55,1184.46,1184.26,1198.85,1223.97,1231.54,1205.5,1193.0,1184.62,1173.02,1168.49,1173.31,1194.43,1200.49,1205.92,1215.0,1207.15,1203.84,1197.25,1202.16,1204.62,1217.87,1221.1,1227.13,1236.34,1236.37,1248.84,1264.55,1256.0,1263.45,1272.18,1287.58,1188.48,1168.08,1162.61,1185.4,1189.39,1174.1,1166.27,1162.38,1164.27,1132.03,1120.44,1164.21,1178.98,1162.3,1138.85,1149.63,1151.42,1140.77,1133.47,1134.15,1116.46,1117.95,1103.63,1036.23,1053.05,1042.22,1044.34,1066.04,1080.38,1078.72,1077.03,1088.77,1085.35,1092.5,1103.6,1102.33,1111.42,1121.88,1115.52,1086.35,1079.8,1076.01,1080.91,1097.95,1111.25,1121.58,1131.59,1116.35,1124.83,1140.48,1144.21,1144.9,1150.34,1153.58,1146.35,1146.33,1130.1,1138.07,1146.21,1137.81,1132.12,1250.41,1239.41,1225.14,1216.68,1209.01,1193.99,1152.32,1169.95,1173.99,1204.8,1188.01,1174.71,1197.27,1164.29,1167.26,1177.6,1198.45,1182.69,1191.25,1189.53,1151.29,1168.89,1167.84,1171.02,1192.85,1188.1,1168.39,1181.41,1211.38,1204.93,1204.41,1206.0,1220.17,1234.25,1239.56,1231.3,1229.15,1232.41,1238.71,1229.93,1234.03,1218.76,1246.52,1241.39,1225.09,1219.0,1205.1,1176.63,1187.83,1209.0,1207.68,1189.13,1202.31,1208.67,1215.45,1217.14,1243.01,1243.64,1253.07,1245.49,1246.15,1242.8,1259.13,1260.99,1265.13,1290.0,1262.62,1261.29,1260.11,1273.74,1291.37,1292.03,1291.8,1308.86,1311.37,1299.19,1298.8,1298.0,1311.46,1334.87,1320.7,1315.46,1303.05,1301.35,1295.34,1306.69,1313.55,1312.99,1304.96,1289.92,1295.28,1320.54,1328.13,1340.62,1343.56,1344.66,1345.02,1350.27,1347.83,1361.17,1355.12,1352.62,1356.04,1349.59,1348.84,1343.56,1360.4,1351.89,1336.14,1337.02,1367.37,1360.66,1394.21,1393.34,1404.32,1419.83,1429.73,1439.23,1430.88,1439.2,1451.7,1480.39,1484.4,1485.95,1486.65,1466.71,1433.9,1452.56,1458.63,1455.84,1434.23,1485.94,1447.07,1448.23,1476.23,1479.23,1508.68,1508.79,1518.27,1514.66,1520.74,1519.67,1526.69,1518.15,1485.11,1421.59,1388.45,1393.18,1318.09,1339.33,1389.11,1341.39,1386.52,1319.04,1298.41,1215.56,1280.39,1215.41,1114.91,1219.73,1084.33,1119.8,1096.8,1115.29,1072.32,1056.62,1134.46,1102.49,1161.75,1110.71,1146.82,1162.81,1105.62,1120.84,1097.88,1186.92,1186.51,1210.28,1211.45,1217.56,1269.23,1262.47,1263.47,1283.25,1266.61,1216.34,1263.21,1276.31,1279.31,1275.88,1233.67,1341.48,1348.66,1320.61,1326.8,1351.11,1347.3,1372.56,1388.37,1403.26,1375.74,1349.33,1356.13,1373.19,1383.94,1373.48,1406.72,1402.8,1410.42,1417.02,1417.84,1416.73,1428.92,1431.82,1439.22,1436.38,1412.18,1438.39,1446.61,1456.16,1465.85,1403.84,1413.18,1419.85,1442.72,1451.12,1435.96,1431.72,1451.86,1464.41,1431.97,1441.33,1359.9,1394.97,1413.61,1438.04,1464.7,1495.7,1485.18,1496.0,1510.99,1541.74,1511.34,1520.58,1513.64,1518.0,1515.55,1565.72,1558.42,1568.49,1515.68,1511.87,1530.2,1500.34,1522.02,1531.45,1482.96,1474.45,1464.97,1473.61,1500.1,1494.49,1496.1,1480.32,1506.62,1518.45,1507.73,1517.98,1558.6,1547.53,1581.75,1580.42,1588.2,1608.22,1652.38,1634.33,1644.41,1634.18,1660.71,1728.28,1641.84,1591.04,1532.39,1556.96,1532.02,1520.72,1519.28,1541.44,1520.9,1495.53,1459.99,1431.16,1465.46,1415.21,1428.29,1444.96,1464.52,1469.33,1469.6,1490.09,1458.42,1486.02,1453.44,1460.29,1485.93,1515.22,1569.15,1571.68,1568.08,1559.13,1573.01,1534.61,1555.93,1593.31,1615.33,1641.0,1590.45,1604.26,1516.62,1567.24,1621.01,1626.03,1650.21,1749.13,1763.37,1761.75,1763.0,1740.39,1752.71,1749.84,1777.02,1781.38,1770.15,1746.78,1763.92,1742.19,1734.86,1768.88,1771.43,1793.19,1760.74,1798.1,1827.95,1826.77,1827.99,1819.48,1818.55,1784.13,1775.33,1781.77,1760.06,1767.77,1763.0,1747.9,1731.01,1739.37,1723.5,1732.38,1738.85,1776.09,1758.72,1739.52,1751.88,1728.24,1740.92,1735.29,1787.25,1807.21,1766.72,1746.55,1754.4,1740.18,1736.19,1790.86,1886.9,1891.25,1901.05,1899.4,1917.24,1830.79,1863.11,1835.74,1901.35,1927.51,2070.07,2062.37,2098.0,2092.91,2083.51,2095.38,2095.89,2104.11,2121.9,2128.31,2117.2,2101.14,2064.88,2070.86,2095.17,2031.36,2036.86,2081.51,2075.84,2026.71,2049.09,2108.54,2024.17,2052.7,2055.03,2114.77,2061.92,2066.49,2092.52,2091.08,2036.22,2043.2,2038.59,2052.96,2045.06,2044.36,2035.55,2055.95,2055.54,2068.63,2137.75,2225.55,2224.75,2249.68,2265.44,2285.88,2254.79,2267.27,2254.84,2296.66,2297.76,2302.4,2293.63,2293.29,2267.92,2315.3,2326.74,2307.12,2379.91,2429.89,2410.12,2395.17,2354.25,2356.74,2381.35,2398.69,2341.66,2308.76,2239.08,2261.97,2316.16,2321.41,2303.43,2308.71,2356.09,2345.1,2406.67,2409.07,2433.53,2402.51,2411.56,2429.81,2421.28,2404.61,2451.76,2466.09,2482.85,2491.4,2521.6,2513.93],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"rgb(255, 127, 14)\",\"width\":2},\"marker\":{\"color\":\"rgb(255, 127, 14)\",\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Exponential Smoothing\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257],\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,2403.9411,2411.9581,2429.312,2433.7358,2422.0932,2443.1247,2450.6878,2445.1502,2453.2036,2470.753,2475.1514,2463.2106],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"showlegend\":true,\"title\":{\"text\":\"Actual vs. Forecast (Out-of-Sample)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bbac7dbc-d8d9-44e8-a1fc-b344b53d7b66');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9fffcbbb-3cad-4e4a-bda4-1bbb2d93bfe0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9fffcbbb-3cad-4e4a-bda4-1bbb2d93bfe0\")) {                    Plotly.newPlot(                        \"9fffcbbb-3cad-4e4a-bda4-1bbb2d93bfe0\",                        [{\"line\":{\"color\":\"rgb(31, 119, 180)\",\"width\":2},\"marker\":{\"color\":\"rgb(31, 119, 180)\",\"size\":5},\"mode\":\"lines+markers\",\"name\":\"adjClose\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281],\"y\":[718.27,718.92,710.36,691.72,693.71,695.94,697.46,701.87,675.22,668.26,680.04,684.11,692.1,699.21,694.49,697.77,695.36,705.63,715.09,720.64,716.98,720.95,719.85,733.78,736.96,741.19,738.63,742.74,739.77,738.42,741.77,745.91,768.79,772.88,771.07,773.18,771.61,782.22,781.76,784.26,784.68,784.85,783.22,782.44,777.14,779.91,777.5,775.42,772.15,772.08,769.64,769.41,769.54,772.15,769.09,767.05,768.78,771.46,780.08,780.35,775.32,759.66,769.02,759.69,762.49,771.76,768.88,765.7,771.41,776.22,787.21,786.9,774.21,783.01,781.56,775.01,777.29,772.56,776.43,776.47,776.86,775.08,785.94,783.07,786.14,778.19,778.53,779.96,795.26,801.56,796.97,799.37,813.11,807.67,799.07,795.35,795.37,784.54,783.61,768.7,762.13,762.02,782.52,790.51,785.31,762.56,754.02,736.08,758.49,764.48,771.23,760.54,769.2,768.27,760.99,761.68,768.24,770.84,758.04,747.92,750.5,762.52,759.11,771.19,776.42,789.29,789.27,796.1,797.07,797.85,790.8,794.2,796.42,794.56,791.26,789.91,791.55,785.05,782.79,771.82,786.14,786.9,794.02,806.15,806.65,804.79,807.91,806.36,807.88,804.61,806.07,802.175,805.02,819.31,823.87,835.67,832.15,823.31,802.32,796.79,795.695,798.53,801.49,801.34,806.97,808.38,809.56,813.67,819.24,820.45,818.98,824.16,828.07,831.66,830.76,831.33,828.64,829.28,823.21,835.24,830.63,829.08,827.78,831.91,835.37,838.68,843.25,845.54,845.62,847.2,848.78,852.12,848.4,830.46,829.59,817.58,814.43,819.51,820.92,831.41,831.5,829.56,838.55,834.57,831.41,827.88,824.67,824.73,823.35,824.32,823.56,837.17,836.82,838.21,841.65,843.19,862.76,872.3,871.73,874.25,905.96,912.57,916.44,927.04,931.66,927.13,934.3,932.17,928.78,930.6,932.22,937.08,943.0,919.62,930.24,934.01,941.86,948.82,954.96,969.54,971.47,975.88,964.86,966.95,975.6,983.68,976.57,980.94,983.41,949.83,942.9,953.4,950.76,942.31,939.78,957.37,950.63,959.45,957.09,965.59,952.27,927.33,940.49,917.79,908.73,898.7,911.71,906.69,918.59,928.8,930.09,943.83,947.16,955.99,953.42,965.4,970.89,968.15,972.92,980.34,950.7,947.8,934.09,941.53,930.5,930.83,930.39,923.65,927.96,929.36,926.79,922.9,907.24,914.39,922.67,922.22,926.96,910.98,910.67,906.66,924.69,927.0,921.28,915.89,913.81,921.29,929.57,939.33,937.34,928.45,927.81,935.95,926.5,929.08,932.07,935.09,925.11,920.29,915.0,921.81,931.58,932.45,928.53,920.97,924.86,944.49,949.5,959.11,953.27,957.79,951.68,969.96,978.89,977.0,972.6,989.25,987.83,989.68,992.0,992.18,992.81,984.45,988.2,968.45,970.54,973.33,972.56,1019.27,1017.11,1016.64,1025.5,1025.58,1032.48,1025.9,1033.33,1039.85,1031.26,1028.07,1025.75,1026.0,1020.91,1032.5,1019.09,1018.38,1034.49,1035.96,1040.61,1054.21,1047.41,1021.66,1021.41,1010.17,998.68,1005.15,1018.38,1030.93,1037.05,1041.1,1040.48,1040.61,1049.15,1064.19,1077.14,1070.68,1064.95,1063.63,1060.12,1056.74,1049.37,1048.14,1046.4,1065.0,1082.48,1086.4,1102.23,1106.94,1106.26,1102.61,1105.52,1122.26,1121.76,1131.98,1129.79,1137.51,1155.81,1169.97,1164.24,1170.37,1175.84,1175.58,1163.69,1169.94,1167.7,1111.9,1055.8,1080.6,1048.58,1001.52,1037.78,1051.94,1052.1,1069.7,1089.52,1094.8,1102.46,1111.34,1106.63,1126.79,1143.75,1118.29,1104.73,1069.52,1078.92,1090.93,1095.06,1109.64,1126.0,1160.04,1164.5,1138.17,1149.49,1149.58,1135.73,1099.82,1097.71,1090.88,1049.08,1021.57,1053.21,1005.1,1004.56,1031.79,1006.47,1013.41,1025.14,1027.81,1007.04,1015.45,1031.64,1019.97,1032.51,1029.27,1037.98,1074.16,1072.08,1087.7,1072.96,1067.45,1019.98,1021.18,1040.04,1030.05,1017.33,1037.31,1024.38,1023.72,1048.21,1054.79,1053.91,1082.76,1097.57,1098.26,1100.2,1079.23,1081.77,1078.59,1066.36,1079.58,1069.73,1079.69,1079.24,1075.66,1060.32,1067.8,1084.99,1119.5,1139.29,1139.66,1136.88,1123.86,1120.87,1129.99,1139.32,1134.79,1152.12,1152.26,1173.46,1168.06,1169.84,1157.66,1155.48,1124.81,1118.46,1103.98,1114.22,1115.65,1127.46,1102.89,1124.27,1140.17,1154.05,1152.84,1153.9,1183.48,1188.82,1183.86,1198.8,1195.88,1186.96,1184.91,1205.5,1248.08,1263.7,1268.33,1238.5,1219.74,1217.26,1220.01,1226.15,1223.71,1224.77,1242.22,1245.61,1249.1,1237.61,1235.01,1242.1,1214.38,1206.49,1200.96,1207.77,1201.62,1207.33,1205.38,1220.65,1241.82,1231.15,1249.3,1239.12,1218.19,1197.0,1186.48,1171.44,1164.83,1164.64,1177.36,1162.82,1175.33,1172.53,1156.05,1161.22,1171.09,1186.87,1166.09,1173.37,1184.65,1180.49,1194.64,1193.47,1195.31,1200.11,1202.95,1168.19,1157.35,1148.97,1138.82,1081.22,1079.32,1110.08,1092.25,1121.28,1115.69,1087.97,1096.46,1101.16,1103.69,1050.71,1095.57,1071.47,1020.08,1036.21,1076.77,1070.0,1057.79,1040.09,1055.81,1093.39,1082.4,1066.15,1038.63,1036.05,1043.66,1064.71,1061.49,1020.0,1025.76,1037.61,1023.88,1048.62,1044.41,1086.23,1088.3,1094.43,1106.43,1050.82,1068.73,1036.58,1039.55,1051.75,1063.68,1061.9,1042.1,1016.53,1028.71,1023.01,1009.41,979.54,976.22,1039.46,1043.88,1037.08,1035.61,1045.85,1016.06,1070.71,1068.39,1076.28,1074.66,1070.33,1057.19,1044.69,1077.15,1080.97,1089.9,1098.26,1070.52,1075.57,1073.9,1090.99,1070.08,1060.62,1089.06,1116.37,1110.75,1132.8,1145.99,1115.23,1098.71,1095.06,1095.01,1121.37,1120.16,1121.67,1113.65,1118.56,1113.8,1096.97,1110.37,1109.4,1115.13,1116.05,1119.92,1140.99,1147.8,1162.03,1157.86,1143.3,1142.32,1175.76,1193.2,1193.32,1185.55,1184.46,1184.26,1198.85,1223.97,1231.54,1205.5,1193.0,1184.62,1173.02,1168.49,1173.31,1194.43,1200.49,1205.92,1215.0,1207.15,1203.84,1197.25,1202.16,1204.62,1217.87,1221.1,1227.13,1236.34,1236.37,1248.84,1264.55,1256.0,1263.45,1272.18,1287.58,1188.48,1168.08,1162.61,1185.4,1189.39,1174.1,1166.27,1162.38,1164.27,1132.03,1120.44,1164.21,1178.98,1162.3,1138.85,1149.63,1151.42,1140.77,1133.47,1134.15,1116.46,1117.95,1103.63,1036.23,1053.05,1042.22,1044.34,1066.04,1080.38,1078.72,1077.03,1088.77,1085.35,1092.5,1103.6,1102.33,1111.42,1121.88,1115.52,1086.35,1079.8,1076.01,1080.91,1097.95,1111.25,1121.58,1131.59,1116.35,1124.83,1140.48,1144.21,1144.9,1150.34,1153.58,1146.35,1146.33,1130.1,1138.07,1146.21,1137.81,1132.12,1250.41,1239.41,1225.14,1216.68,1209.01,1193.99,1152.32,1169.95,1173.99,1204.8,1188.01,1174.71,1197.27,1164.29,1167.26,1177.6,1198.45,1182.69,1191.25,1189.53,1151.29,1168.89,1167.84,1171.02,1192.85,1188.1,1168.39,1181.41,1211.38,1204.93,1204.41,1206.0,1220.17,1234.25,1239.56,1231.3,1229.15,1232.41,1238.71,1229.93,1234.03,1218.76,1246.52,1241.39,1225.09,1219.0,1205.1,1176.63,1187.83,1209.0,1207.68,1189.13,1202.31,1208.67,1215.45,1217.14,1243.01,1243.64,1253.07,1245.49,1246.15,1242.8,1259.13,1260.99,1265.13,1290.0,1262.62,1261.29,1260.11,1273.74,1291.37,1292.03,1291.8,1308.86,1311.37,1299.19,1298.8,1298.0,1311.46,1334.87,1320.7,1315.46,1303.05,1301.35,1295.34,1306.69,1313.55,1312.99,1304.96,1289.92,1295.28,1320.54,1328.13,1340.62,1343.56,1344.66,1345.02,1350.27,1347.83,1361.17,1355.12,1352.62,1356.04,1349.59,1348.84,1343.56,1360.4,1351.89,1336.14,1337.02,1367.37,1360.66,1394.21,1393.34,1404.32,1419.83,1429.73,1439.23,1430.88,1439.2,1451.7,1480.39,1484.4,1485.95,1486.65,1466.71,1433.9,1452.56,1458.63,1455.84,1434.23,1485.94,1447.07,1448.23,1476.23,1479.23,1508.68,1508.79,1518.27,1514.66,1520.74,1519.67,1526.69,1518.15,1485.11,1421.59,1388.45,1393.18,1318.09,1339.33,1389.11,1341.39,1386.52,1319.04,1298.41,1215.56,1280.39,1215.41,1114.91,1219.73,1084.33,1119.8,1096.8,1115.29,1072.32,1056.62,1134.46,1102.49,1161.75,1110.71,1146.82,1162.81,1105.62,1120.84,1097.88,1186.92,1186.51,1210.28,1211.45,1217.56,1269.23,1262.47,1263.47,1283.25,1266.61,1216.34,1263.21,1276.31,1279.31,1275.88,1233.67,1341.48,1348.66,1320.61,1326.8,1351.11,1347.3,1372.56,1388.37,1403.26,1375.74,1349.33,1356.13,1373.19,1383.94,1373.48,1406.72,1402.8,1410.42,1417.02,1417.84,1416.73,1428.92,1431.82,1439.22,1436.38,1412.18,1438.39,1446.61,1456.16,1465.85,1403.84,1413.18,1419.85,1442.72,1451.12,1435.96,1431.72,1451.86,1464.41,1431.97,1441.33,1359.9,1394.97,1413.61,1438.04,1464.7,1495.7,1485.18,1496.0,1510.99,1541.74,1511.34,1520.58,1513.64,1518.0,1515.55,1565.72,1558.42,1568.49,1515.68,1511.87,1530.2,1500.34,1522.02,1531.45,1482.96,1474.45,1464.97,1473.61,1500.1,1494.49,1496.1,1480.32,1506.62,1518.45,1507.73,1517.98,1558.6,1547.53,1581.75,1580.42,1588.2,1608.22,1652.38,1634.33,1644.41,1634.18,1660.71,1728.28,1641.84,1591.04,1532.39,1556.96,1532.02,1520.72,1519.28,1541.44,1520.9,1495.53,1459.99,1431.16,1465.46,1415.21,1428.29,1444.96,1464.52,1469.33,1469.6,1490.09,1458.42,1486.02,1453.44,1460.29,1485.93,1515.22,1569.15,1571.68,1568.08,1559.13,1573.01,1534.61,1555.93,1593.31,1615.33,1641.0,1590.45,1604.26,1516.62,1567.24,1621.01,1626.03,1650.21,1749.13,1763.37,1761.75,1763.0,1740.39,1752.71,1749.84,1777.02,1781.38,1770.15,1746.78,1763.92,1742.19,1734.86,1768.88,1771.43,1793.19,1760.74,1798.1,1827.95,1826.77,1827.99,1819.48,1818.55,1784.13,1775.33,1781.77,1760.06,1767.77,1763.0,1747.9,1731.01,1739.37,1723.5,1732.38,1738.85,1776.09,1758.72,1739.52,1751.88,1728.24,1740.92,1735.29,1787.25,1807.21,1766.72,1746.55,1754.4,1740.18,1736.19,1790.86,1886.9,1891.25,1901.05,1899.4,1917.24,1830.79,1863.11,1835.74,1901.35,1927.51,2070.07,2062.37,2098.0,2092.91,2083.51,2095.38,2095.89,2104.11,2121.9,2128.31,2117.2,2101.14,2064.88,2070.86,2095.17,2031.36,2036.86,2081.51,2075.84,2026.71,2049.09,2108.54,2024.17,2052.7,2055.03,2114.77,2061.92,2066.49,2092.52,2091.08,2036.22,2043.2,2038.59,2052.96,2045.06,2044.36,2035.55,2055.95,2055.54,2068.63,2137.75,2225.55,2224.75,2249.68,2265.44,2285.88,2254.79,2267.27,2254.84,2296.66,2297.76,2302.4,2293.63,2293.29,2267.92,2315.3,2326.74,2307.12,2379.91,2429.89,2410.12,2395.17,2354.25,2356.74,2381.35,2398.69,2341.66,2308.76,2239.08,2261.97,2316.16,2321.41,2303.43,2308.71,2356.09,2345.1,2406.67,2409.07,2433.53,2402.51,2411.56,2429.81,2421.28,2404.61,2451.76,2466.09,2482.85,2491.4,2521.6,2513.93,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"rgb(255, 127, 14)\",\"width\":2},\"marker\":{\"color\":\"rgb(255, 127, 14)\",\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Exponential Smoothing\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281],\"y\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,2403.9411,2411.9581,2429.312,2433.7358,2422.0932,2443.1247,2450.6878,2445.1502,2453.2036,2470.753,2475.1514,2463.2106,2484.4989,2492.0899,2486.3593,2494.4491,2512.194,2516.5669,2504.3281,2525.8731,2533.4919,2527.5683,2535.6946,2553.635,2557.9825,2545.4456,2567.2472,2574.894,2568.7774,2576.9401,2595.0761,2599.398,2586.563,2608.6214,2616.2961,2609.9865],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"showlegend\":true,\"title\":{\"text\":\"Actual vs. Forecast (Out-of-Sample)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9fffcbbb-3cad-4e4a-bda4-1bbb2d93bfe0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"fb860291-7164-4962-8096-290b030494c3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb860291-7164-4962-8096-290b030494c3\")) {                    Plotly.newPlot(                        \"fb860291-7164-4962-8096-290b030494c3\",                        [{\"line\":{\"color\":\"rgb(31, 119, 180)\",\"width\":2},\"marker\":{\"color\":\"rgb(31, 119, 180)\",\"size\":5},\"mode\":\"lines+markers\",\"name\":\"adjClose\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257],\"y\":[718.27,718.92,710.36,691.72,693.71,695.94,697.46,701.87,675.22,668.26,680.04,684.11,692.1,699.21,694.49,697.77,695.36,705.63,715.09,720.64,716.98,720.95,719.85,733.78,736.96,741.19,738.63,742.74,739.77,738.42,741.77,745.91,768.79,772.88,771.07,773.18,771.61,782.22,781.76,784.26,784.68,784.85,783.22,782.44,777.14,779.91,777.5,775.42,772.15,772.08,769.64,769.41,769.54,772.15,769.09,767.05,768.78,771.46,780.08,780.35,775.32,759.66,769.02,759.69,762.49,771.76,768.88,765.7,771.41,776.22,787.21,786.9,774.21,783.01,781.56,775.01,777.29,772.56,776.43,776.47,776.86,775.08,785.94,783.07,786.14,778.19,778.53,779.96,795.26,801.56,796.97,799.37,813.11,807.67,799.07,795.35,795.37,784.54,783.61,768.7,762.13,762.02,782.52,790.51,785.31,762.56,754.02,736.08,758.49,764.48,771.23,760.54,769.2,768.27,760.99,761.68,768.24,770.84,758.04,747.92,750.5,762.52,759.11,771.19,776.42,789.29,789.27,796.1,797.07,797.85,790.8,794.2,796.42,794.56,791.26,789.91,791.55,785.05,782.79,771.82,786.14,786.9,794.02,806.15,806.65,804.79,807.91,806.36,807.88,804.61,806.07,802.175,805.02,819.31,823.87,835.67,832.15,823.31,802.32,796.79,795.695,798.53,801.49,801.34,806.97,808.38,809.56,813.67,819.24,820.45,818.98,824.16,828.07,831.66,830.76,831.33,828.64,829.28,823.21,835.24,830.63,829.08,827.78,831.91,835.37,838.68,843.25,845.54,845.62,847.2,848.78,852.12,848.4,830.46,829.59,817.58,814.43,819.51,820.92,831.41,831.5,829.56,838.55,834.57,831.41,827.88,824.67,824.73,823.35,824.32,823.56,837.17,836.82,838.21,841.65,843.19,862.76,872.3,871.73,874.25,905.96,912.57,916.44,927.04,931.66,927.13,934.3,932.17,928.78,930.6,932.22,937.08,943.0,919.62,930.24,934.01,941.86,948.82,954.96,969.54,971.47,975.88,964.86,966.95,975.6,983.68,976.57,980.94,983.41,949.83,942.9,953.4,950.76,942.31,939.78,957.37,950.63,959.45,957.09,965.59,952.27,927.33,940.49,917.79,908.73,898.7,911.71,906.69,918.59,928.8,930.09,943.83,947.16,955.99,953.42,965.4,970.89,968.15,972.92,980.34,950.7,947.8,934.09,941.53,930.5,930.83,930.39,923.65,927.96,929.36,926.79,922.9,907.24,914.39,922.67,922.22,926.96,910.98,910.67,906.66,924.69,927.0,921.28,915.89,913.81,921.29,929.57,939.33,937.34,928.45,927.81,935.95,926.5,929.08,932.07,935.09,925.11,920.29,915.0,921.81,931.58,932.45,928.53,920.97,924.86,944.49,949.5,959.11,953.27,957.79,951.68,969.96,978.89,977.0,972.6,989.25,987.83,989.68,992.0,992.18,992.81,984.45,988.2,968.45,970.54,973.33,972.56,1019.27,1017.11,1016.64,1025.5,1025.58,1032.48,1025.9,1033.33,1039.85,1031.26,1028.07,1025.75,1026.0,1020.91,1032.5,1019.09,1018.38,1034.49,1035.96,1040.61,1054.21,1047.41,1021.66,1021.41,1010.17,998.68,1005.15,1018.38,1030.93,1037.05,1041.1,1040.48,1040.61,1049.15,1064.19,1077.14,1070.68,1064.95,1063.63,1060.12,1056.74,1049.37,1048.14,1046.4,1065.0,1082.48,1086.4,1102.23,1106.94,1106.26,1102.61,1105.52,1122.26,1121.76,1131.98,1129.79,1137.51,1155.81,1169.97,1164.24,1170.37,1175.84,1175.58,1163.69,1169.94,1167.7,1111.9,1055.8,1080.6,1048.58,1001.52,1037.78,1051.94,1052.1,1069.7,1089.52,1094.8,1102.46,1111.34,1106.63,1126.79,1143.75,1118.29,1104.73,1069.52,1078.92,1090.93,1095.06,1109.64,1126.0,1160.04,1164.5,1138.17,1149.49,1149.58,1135.73,1099.82,1097.71,1090.88,1049.08,1021.57,1053.21,1005.1,1004.56,1031.79,1006.47,1013.41,1025.14,1027.81,1007.04,1015.45,1031.64,1019.97,1032.51,1029.27,1037.98,1074.16,1072.08,1087.7,1072.96,1067.45,1019.98,1021.18,1040.04,1030.05,1017.33,1037.31,1024.38,1023.72,1048.21,1054.79,1053.91,1082.76,1097.57,1098.26,1100.2,1079.23,1081.77,1078.59,1066.36,1079.58,1069.73,1079.69,1079.24,1075.66,1060.32,1067.8,1084.99,1119.5,1139.29,1139.66,1136.88,1123.86,1120.87,1129.99,1139.32,1134.79,1152.12,1152.26,1173.46,1168.06,1169.84,1157.66,1155.48,1124.81,1118.46,1103.98,1114.22,1115.65,1127.46,1102.89,1124.27,1140.17,1154.05,1152.84,1153.9,1183.48,1188.82,1183.86,1198.8,1195.88,1186.96,1184.91,1205.5,1248.08,1263.7,1268.33,1238.5,1219.74,1217.26,1220.01,1226.15,1223.71,1224.77,1242.22,1245.61,1249.1,1237.61,1235.01,1242.1,1214.38,1206.49,1200.96,1207.77,1201.62,1207.33,1205.38,1220.65,1241.82,1231.15,1249.3,1239.12,1218.19,1197.0,1186.48,1171.44,1164.83,1164.64,1177.36,1162.82,1175.33,1172.53,1156.05,1161.22,1171.09,1186.87,1166.09,1173.37,1184.65,1180.49,1194.64,1193.47,1195.31,1200.11,1202.95,1168.19,1157.35,1148.97,1138.82,1081.22,1079.32,1110.08,1092.25,1121.28,1115.69,1087.97,1096.46,1101.16,1103.69,1050.71,1095.57,1071.47,1020.08,1036.21,1076.77,1070.0,1057.79,1040.09,1055.81,1093.39,1082.4,1066.15,1038.63,1036.05,1043.66,1064.71,1061.49,1020.0,1025.76,1037.61,1023.88,1048.62,1044.41,1086.23,1088.3,1094.43,1106.43,1050.82,1068.73,1036.58,1039.55,1051.75,1063.68,1061.9,1042.1,1016.53,1028.71,1023.01,1009.41,979.54,976.22,1039.46,1043.88,1037.08,1035.61,1045.85,1016.06,1070.71,1068.39,1076.28,1074.66,1070.33,1057.19,1044.69,1077.15,1080.97,1089.9,1098.26,1070.52,1075.57,1073.9,1090.99,1070.08,1060.62,1089.06,1116.37,1110.75,1132.8,1145.99,1115.23,1098.71,1095.06,1095.01,1121.37,1120.16,1121.67,1113.65,1118.56,1113.8,1096.97,1110.37,1109.4,1115.13,1116.05,1119.92,1140.99,1147.8,1162.03,1157.86,1143.3,1142.32,1175.76,1193.2,1193.32,1185.55,1184.46,1184.26,1198.85,1223.97,1231.54,1205.5,1193.0,1184.62,1173.02,1168.49,1173.31,1194.43,1200.49,1205.92,1215.0,1207.15,1203.84,1197.25,1202.16,1204.62,1217.87,1221.1,1227.13,1236.34,1236.37,1248.84,1264.55,1256.0,1263.45,1272.18,1287.58,1188.48,1168.08,1162.61,1185.4,1189.39,1174.1,1166.27,1162.38,1164.27,1132.03,1120.44,1164.21,1178.98,1162.3,1138.85,1149.63,1151.42,1140.77,1133.47,1134.15,1116.46,1117.95,1103.63,1036.23,1053.05,1042.22,1044.34,1066.04,1080.38,1078.72,1077.03,1088.77,1085.35,1092.5,1103.6,1102.33,1111.42,1121.88,1115.52,1086.35,1079.8,1076.01,1080.91,1097.95,1111.25,1121.58,1131.59,1116.35,1124.83,1140.48,1144.21,1144.9,1150.34,1153.58,1146.35,1146.33,1130.1,1138.07,1146.21,1137.81,1132.12,1250.41,1239.41,1225.14,1216.68,1209.01,1193.99,1152.32,1169.95,1173.99,1204.8,1188.01,1174.71,1197.27,1164.29,1167.26,1177.6,1198.45,1182.69,1191.25,1189.53,1151.29,1168.89,1167.84,1171.02,1192.85,1188.1,1168.39,1181.41,1211.38,1204.93,1204.41,1206.0,1220.17,1234.25,1239.56,1231.3,1229.15,1232.41,1238.71,1229.93,1234.03,1218.76,1246.52,1241.39,1225.09,1219.0,1205.1,1176.63,1187.83,1209.0,1207.68,1189.13,1202.31,1208.67,1215.45,1217.14,1243.01,1243.64,1253.07,1245.49,1246.15,1242.8,1259.13,1260.99,1265.13,1290.0,1262.62,1261.29,1260.11,1273.74,1291.37,1292.03,1291.8,1308.86,1311.37,1299.19,1298.8,1298.0,1311.46,1334.87,1320.7,1315.46,1303.05,1301.35,1295.34,1306.69,1313.55,1312.99,1304.96,1289.92,1295.28,1320.54,1328.13,1340.62,1343.56,1344.66,1345.02,1350.27,1347.83,1361.17,1355.12,1352.62,1356.04,1349.59,1348.84,1343.56,1360.4,1351.89,1336.14,1337.02,1367.37,1360.66,1394.21,1393.34,1404.32,1419.83,1429.73,1439.23,1430.88,1439.2,1451.7,1480.39,1484.4,1485.95,1486.65,1466.71,1433.9,1452.56,1458.63,1455.84,1434.23,1485.94,1447.07,1448.23,1476.23,1479.23,1508.68,1508.79,1518.27,1514.66,1520.74,1519.67,1526.69,1518.15,1485.11,1421.59,1388.45,1393.18,1318.09,1339.33,1389.11,1341.39,1386.52,1319.04,1298.41,1215.56,1280.39,1215.41,1114.91,1219.73,1084.33,1119.8,1096.8,1115.29,1072.32,1056.62,1134.46,1102.49,1161.75,1110.71,1146.82,1162.81,1105.62,1120.84,1097.88,1186.92,1186.51,1210.28,1211.45,1217.56,1269.23,1262.47,1263.47,1283.25,1266.61,1216.34,1263.21,1276.31,1279.31,1275.88,1233.67,1341.48,1348.66,1320.61,1326.8,1351.11,1347.3,1372.56,1388.37,1403.26,1375.74,1349.33,1356.13,1373.19,1383.94,1373.48,1406.72,1402.8,1410.42,1417.02,1417.84,1416.73,1428.92,1431.82,1439.22,1436.38,1412.18,1438.39,1446.61,1456.16,1465.85,1403.84,1413.18,1419.85,1442.72,1451.12,1435.96,1431.72,1451.86,1464.41,1431.97,1441.33,1359.9,1394.97,1413.61,1438.04,1464.7,1495.7,1485.18,1496.0,1510.99,1541.74,1511.34,1520.58,1513.64,1518.0,1515.55,1565.72,1558.42,1568.49,1515.68,1511.87,1530.2,1500.34,1522.02,1531.45,1482.96,1474.45,1464.97,1473.61,1500.1,1494.49,1496.1,1480.32,1506.62,1518.45,1507.73,1517.98,1558.6,1547.53,1581.75,1580.42,1588.2,1608.22,1652.38,1634.33,1644.41,1634.18,1660.71,1728.28,1641.84,1591.04,1532.39,1556.96,1532.02,1520.72,1519.28,1541.44,1520.9,1495.53,1459.99,1431.16,1465.46,1415.21,1428.29,1444.96,1464.52,1469.33,1469.6,1490.09,1458.42,1486.02,1453.44,1460.29,1485.93,1515.22,1569.15,1571.68,1568.08,1559.13,1573.01,1534.61,1555.93,1593.31,1615.33,1641.0,1590.45,1604.26,1516.62,1567.24,1621.01,1626.03,1650.21,1749.13,1763.37,1761.75,1763.0,1740.39,1752.71,1749.84,1777.02,1781.38,1770.15,1746.78,1763.92,1742.19,1734.86,1768.88,1771.43,1793.19,1760.74,1798.1,1827.95,1826.77,1827.99,1819.48,1818.55,1784.13,1775.33,1781.77,1760.06,1767.77,1763.0,1747.9,1731.01,1739.37,1723.5,1732.38,1738.85,1776.09,1758.72,1739.52,1751.88,1728.24,1740.92,1735.29,1787.25,1807.21,1766.72,1746.55,1754.4,1740.18,1736.19,1790.86,1886.9,1891.25,1901.05,1899.4,1917.24,1830.79,1863.11,1835.74,1901.35,1927.51,2070.07,2062.37,2098.0,2092.91,2083.51,2095.38,2095.89,2104.11,2121.9,2128.31,2117.2,2101.14,2064.88,2070.86,2095.17,2031.36,2036.86,2081.51,2075.84,2026.71,2049.09,2108.54,2024.17,2052.7,2055.03,2114.77,2061.92,2066.49,2092.52,2091.08,2036.22,2043.2,2038.59,2052.96,2045.06,2044.36,2035.55,2055.95,2055.54,2068.63,2137.75,2225.55,2224.75,2249.68,2265.44,2285.88,2254.79,2267.27,2254.84,2296.66,2297.76,2302.4,2293.63,2293.29,2267.92,2315.3,2326.74,2307.12,2379.91,2429.89,2410.12,2395.17,2354.25,2356.74,2381.35,2398.69,2341.66,2308.76,2239.08,2261.97,2316.16,2321.41,2303.43,2308.71,2356.09,2345.1,2406.67,2409.07,2433.53,2402.51,2411.56,2429.81,2421.28,2404.61,2451.76,2466.09,2482.85,2491.4,2521.6,2513.93],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"rgb(255, 127, 14)\",\"width\":2},\"marker\":{\"color\":\"rgb(255, 127, 14)\",\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Exponential Smoothing\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257],\"y\":[0.8470999999999549,4.698199999999929,-4.751899999999978,-16.594799999999964,1.987700000000018,2.7677000000001044,2.670500000000061,6.726800000000026,-22.061199999999985,-5.022699999999986,15.031599999999912,6.868000000000052,8.865499999999997,8.566100000000006,-2.456299999999942,7.6013000000000375,1.0950000000000273,12.141200000000026,10.969600000000014,5.344799999999964,-3.9086999999999534,4.356600000000071,2.598500000000058,16.216299999999933,4.921100000000024,3.76380000000006,-4.401700000000005,2.4008999999999787,-3.072900000000004,1.0043999999999187,4.3706999999999425,4.736400000000003,22.168699999999944,3.73619999999994,-3.9676999999999225,0.6500999999999522,0.20640000000003056,10.524000000000001,-0.288599999999974,-0.45470000000000255,-2.0721000000000913,-2.501199999999926,-3.279199999999946,0.550200000000018,-5.795500000000061,1.9343999999999824,-4.768100000000004,-4.516500000000065,-5.644800000000032,-1.406099999999924,-0.5070000000000618,-0.016600000000039472,0.08159999999998035,0.8017999999999574,-4.550999999999931,-4.038200000000074,0.7010000000000218,5.022000000000048,9.488300000000095,1.0588999999999942,-7.024000000000001,-17.846400000000017,6.248299999999972,-9.323599999999942,4.204899999999952,10.260999999999967,-1.3366999999999507,-4.693399999999997,4.554899999999975,2.9903000000000475,11.017400000000066,2.1306999999999334,-12.869100000000003,8.164899999999989,-2.1293000000000575,-8.182800000000043,-0.9396000000000413,-5.35310000000004,5.348999999999933,1.226099999999974,0.602800000000002,-2.6363000000000056,9.689800000000105,-4.630399999999895,2.074700000000007,-6.35209999999995,0.3850999999999658,1.598799999999983,14.66840000000002,6.059799999999996,-6.65969999999993,0.5806999999999789,15.2192,-4.144800000000032,-9.762399999999957,-6.587400000000002,-2.099199999999996,-12.930000000000064,-3.125,-13.730599999999981,-6.314600000000041,0.2518999999999778,19.981699999999933,9.198399999999992,-5.4442000000000235,-24.495000000000005,-8.789999999999964,-16.97219999999993,22.101200000000063,7.3075999999999794,7.475800000000049,-10.023400000000038,7.801600000000008,1.5966999999999416,-5.389299999999935,-0.7046000000000276,5.671699999999987,2.9504000000000588,-12.041300000000092,-11.851499999999987,3.6924000000000206,14.874900000000025,-2.8034999999999854,10.710700000000088,6.077099999999973,14.28189999999995,0.11230000000000473,7.385400000000004,2.423400000000015,-0.47719999999992524,-9.943200000000047,1.5429000000000315,2.3910999999999376,-2.6195000000000164,-3.3320999999999685,-0.6167000000000371,0.5387999999999238,-8.56490000000008,-4.068399999999997,-10.9849999999999,13.133299999999963,2.8985999999999876,8.65930000000003,11.965799999999945,-0.36390000000005784,-3.5650000000000546,2.8034000000000106,-3.182299999999941,1.7042000000000144,-2.569499999999948,-0.27959999999995944,-5.4978000000000975,1.0014999999999645,14.421399999999949,4.264800000000037,12.272699999999986,-2.128500000000031,-11.345600000000104,-24.022699999999986,-9.509300000000053,-2.157699999999977,2.053099999999972,3.8857000000000426,2.0282000000000835,5.087200000000053,1.341099999999983,-0.5849000000000615,3.4260999999999058,4.733200000000011,1.8016000000000076,0.07410000000004402,3.8301999999999907,3.412900000000036,1.605199999999968,-2.050200000000018,-1.3307999999999538,-2.8641000000000076,1.6743000000000166,-7.515800000000013,10.495700000000056,-5.751899999999978,-3.167100000000005,-3.1025000000000773,4.11119999999994,5.202099999999973,2.584699999999998,3.1762999999999693,0.8434999999999491,-1.186900000000037,-0.3605999999999767,1.1936999999999216,4.424200000000042,-4.752399999999966,-20.27679999999998,-4.2368000000000166,-13.024400000000014,-5.325500000000034,5.290200000000027,3.869899999999916,10.858999999999924,0.7322000000000344,-3.4983000000000857,8.414499999999975,-4.674199999999928,-3.8792000000000826,-2.351599999999962,-3.9564000000000306,-0.29570000000001073,-2.5878000000000156,0.3307000000000926,-1.3453000000000657,13.641700000000014,2.626800000000003,1.0085000000000264,3.11119999999994,0.28480000000001837,18.556600000000003,9.908599999999979,-1.3030999999999722,3.351199999999949,30.443200000000047,7.590000000000032,1.128400000000056,6.866800000000012,2.3093999999999824,-7.163000000000011,6.018399999999929,-5.562000000000012,-5.82650000000001,-2.11869999999999,-2.547900000000027,2.1100999999999885,4.0593000000000075,-23.628299999999967,5.317099999999982,3.2118000000000393,5.173099999999977,3.7871000000000095,3.9177000000000817,12.801199999999994,3.4483999999999924,-0.13750000000004547,-12.996399999999994,-2.958599999999933,4.359300000000076,5.66459999999995,-9.3202,4.164100000000076,-1.5534000000000106,-34.85640000000001,-13.743800000000078,6.1096,-3.6246999999999616,-9.605600000000095,-1.8114000000000487,14.911299999999983,-3.7894000000000005,5.056100000000015,-5.641099999999938,6.704000000000065,-13.266700000000014,-24.94769999999994,7.931400000000053,-19.067000000000007,-13.502099999999928,-13.058599999999956,11.987900000000081,-1.851099999999974,14.988800000000083,8.633399999999938,6.2934999999999945,11.497000000000071,1.8683999999999514,6.910499999999956,-0.7694000000000187,13.235000000000014,2.411299999999983,0.6514999999999418,0.5492999999999029,4.323700000000031,-32.32719999999995,-4.827200000000062,-12.969699999999989,3.175399999999968,-6.423000000000002,-3.147399999999948,-2.480099999999993,-7.088000000000079,5.151299999999992,4.199799999999982,-5.304200000000037,0.49919999999997344,-18.22569999999996,4.133199999999988,9.324499999999944,1.7670000000000528,7.29340000000002,-17.994199999999978,2.7714999999999463,-5.2830000000000155,15.57910000000004,4.037199999999984,-4.0412000000000035,-3.755899999999997,-4.107600000000048,11.203599999999938,7.824299999999994,7.1299999999999955,-1.298599999999965,-7.867799999999988,0.30709999999999127,6.165200000000027,-5.763900000000035,0.16840000000001965,-0.427599999999984,3.437999999999988,-8.076599999999985,-4.078399999999988,-7.7000000000000455,9.97709999999995,9.095700000000079,-1.6060999999999694,-3.8075999999999794,-5.8682999999999765,4.839799999999968,18.19029999999998,9.58579999999995,7.981800000000021,-8.988500000000045,3.260400000000004,-4.339300000000094,18.145399999999995,7.070299999999975,0.9492000000000189,-7.685200000000009,12.107099999999946,-1.6514999999999418,2.717999999999961,1.2211999999999534,-3.6216000000000577,2.446999999999889,-11.346499999999992,-2.0249999999999773,-20.677599999999984,1.554899999999975,2.5593000000000075,-3.294200000000046,49.16649999999993,0.05709999999999127,-6.2409000000000106,7.508100000000013,0.4513999999999214,5.051899999999932,-10.268699999999853,5.9164999999998145,5.773500000000013,-13.808899999999994,-5.897500000000036,-2.7950000000000728,-1.6618000000000848,-8.284400000000119,10.302099999999996,-13.187299999999937,-6.2234999999999445,14.764300000000048,3.3906999999999243,3.4103000000000065,11.076500000000124,-7.301099999999906,-26.755600000000072,-7.310200000000009,-13.225500000000011,-11.223100000000045,5.107300000000009,12.114299999999957,14.2342000000001,8.97460000000001,-0.04010000000016589,-2.0471999999999753,0.8393999999998414,6.747100000000046,12.580699999999979,13.444900000000189,-4.561099999999897,-11.890300000000025,-4.4310999999997875,-3.4962000000000444,-6.133299999999963,-11.3579000000002,-2.599499999999807,0.26060000000006767,14.481399999999894,17.414400000000114,6.108300000000099,13.692399999999907,1.9329000000000178,-2.362100000000055,-3.057600000000093,-3.7146000000000186,13.657999999999902,1.026299999999992,6.586399999999912,-5.764100000000099,5.173399999999901,19.441900000000032,8.8121000000001,-9.557700000000068,4.921699999999873,1.141099999999824,-4.727399999999989,-15.447999999999865,4.511500000000069,-8.586999999999989,-60.0659999999998,-61.27469999999994,17.593399999999974,-30.63409999999999,-48.684099999999944,35.256599999999935,16.66039999999998,4.285199999999804,21.502700000000004,18.499900000000025,8.070799999999963,9.46180000000004,7.868099999999913,-7.207099999999855,20.369300000000067,19.85290000000009,-29.35180000000014,-16.493799999999965,-36.303699999999935,4.602700000000141,11.062599999999975,6.102999999999838,17.044700000000148,15.323000000000093,35.581300000000056,8.431100000000015,-30.72609999999986,4.2590000000000146,-0.08930000000009386,-13.849500000000035,-40.912900000000036,-6.470900000000029,-4.341899999999896,-43.38760000000002,-33.92369999999994,31.430000000000064,-41.04280000000006,-3.3764000000001033,28.850799999999936,-17.26139999999998,7.649400000000014,11.626400000000103,4.615299999999934,-13.811000000000035,6.723400000000083,16.89110000000005,-3.682199999999966,12.961599999999976,-3.991899999999987,8.603399999999965,43.62480000000005,-0.7065999999999804,12.822000000000116,-8.174600000000055,-8.179799999999886,-51.325399999999945,-4.527200000000107,23.968399999999974,-7.993600000000015,-15.438600000000065,25.87239999999997,-10.672599999999875,-1.976799999999912,22.316100000000006,12.629199999999855,0.3288000000000011,26.302400000000034,21.908500000000004,1.8149000000000797,-0.8518999999998869,-26.69309999999996,2.600599999999986,-3.3663000000001375,-16.875400000000127,16.271600000000035,-7.81899999999996,7.30560000000014,-3.412800000000061,-1.8480999999999312,-15.518400000000156,2.6762999999998556,21.262699999999995,37.92370000000005,20.151799999999866,-2.721599999999853,-2.7065999999999804,-14.526299999999992,-10.405700000000024,9.771600000000035,9.80989999999997,-6.891800000000103,12.615299999999934,2.00870000000009,20.603000000000065,-10.337099999999964,0.6996999999998934,-13.501599999999826,-6.677300000000059,-36.29359999999997,-8.304399999999987,-15.360099999999875,5.279999999999973,3.7445000000000164,13.351499999999987,-25.00949999999989,16.72980000000007,19.10660000000007,15.801699999999983,-5.0672000000001844,1.2264999999999873,29.471500000000106,6.602699999999913,-10.334500000000162,13.499900000000025,-2.93119999999999,-15.152000000000044,-3.8321999999998297,18.371599999999944,43.32060000000001,13.554599999999937,3.076999999999998,-31.932999999999993,-28.674099999999953,-6.536000000000058,-0.9345000000000709,4.06470000000013,-6.29320000000007,-0.38380000000006476,18.21440000000007,-0.4499000000000706,1.5610999999998967,-14.965900000000147,-6.468299999999999,2.6947999999999865,-28.371999999999844,-10.124900000000025,-10.110099999999875,5.630100000000084,-6.749400000000151,4.0151999999998225,-4.2159999999998945,16.38890000000015,23.405099999999948,-12.418299999999817,15.3753999999999,-10.279600000000073,-24.376899999999978,-26.435899999999947,-12.10369999999989,-14.8916999999999,-8.724500000000035,-1.1515999999999167,14.524899999999889,-12.56840000000011,10.527100000000019,-0.10000000000013642,-14.548199999999952,3.239900000000034,9.965999999999894,17.919599999999946,-17.836900000000014,3.586899999999787,13.539800000000014,-0.6231000000000222,12.205700000000206,-1.4975999999999203,1.621599999999944,6.963199999999915,-0.013999999999896318,-34.18229999999994,-11.645100000000184,-11.202099999999973,-11.072599999999966,-57.26019999999994,-3.2051000000001295,31.08330000000001,-9.87740000000008,32.14319999999998,-2.6239000000000487,-27.060899999999947,9.761400000000094,8.0471,1.5434999999999945,-47.128400000000056,43.02149999999983,-18.163800000000037,-50.680999999999926,14.980300000000057,45.96149999999989,-2.902599999999893,-4.78410000000008,-18.923000000000002,18.042799999999943,43.44710000000009,-6.969899999999825,-16.640499999999975,-29.05379999999991,2.2967999999998483,7.976000000000113,24.438499999999976,1.6795999999999367,-39.70589999999993,3.5656999999999925,13.915899999999851,-5.647800000000075,23.864399999999932,-0.31209999999987303,44.88930000000005,9.024899999999889,5.039200000000164,11.084700000000112,-49.35500000000002,9.67710000000011,-29.78449999999998,1.0832000000000335,16.835900000000038,12.974699999999984,-1.1735999999998512,-11.798900000000003,-31.61460000000011,12.615200000000073,-3.9454000000000633,-9.959699999999998,-30.607900000000086,-4.686899999999923,72.96720000000005,8.431300000000192,-4.844600000000128,-1.8576000000000477,13.491399999999885,-28.756000000000085,50.86410000000001,7.842100000000073,5.83199999999988,-0.6852999999998701,-5.7693000000001575,-12.080699999999979,-13.232999999999947,26.37869999999998,12.740800000000036,7.079200000000128,9.26649999999995,-28.61590000000001,3.7704999999998563,-1.094899999999825,9.848500000000058,-13.58680000000004,-13.6079000000002,27.94749999999999,30.356899999999996,-2.7661000000000513,21.01800000000003,5.875099999999975,-24.2358999999999,-23.25759999999991,-7.797400000000152,-1.0091999999999643,27.888599999999997,0.3242999999999938,-6.805399999999963,-0.9560999999998785,1.0827999999999065,-7.158400000000029,-18.357899999999972,12.05099999999993,0.419399999999996,-1.667599999999993,8.710800000000063,1.179600000000164,19.125600000000077,8.000299999999925,13.290500000000065,-3.5868000000000393,-23.942099999999982,3.513400000000047,29.87830000000008,16.5766000000001,0.21349999999983993,-10.833100000000059,-2.8625999999999294,-9.261999999999944,19.18179999999984,20.89949999999999,5.177999999999884,-27.204500000000053,-18.05529999999999,-10.881800000000112,-20.73140000000012,-1.3959999999999582,-0.1228000000000975,19.16280000000006,9.284900000000107,4.2724000000000615,8.824800000000096,-15.13149999999996,-0.8114000000000487,-12.372100000000046,0.45839999999998327,4.16619999999989,12.019599999999855,3.7592999999999392,-0.7212999999999283,12.682599999999866,-4.498500000000149,7.540399999999863,17.161299999999983,-10.04379999999992,5.134199999999964,1.3315000000000055,17.93859999999995,-103.52970000000005,-34.80790000000002,-6.130700000000161,23.466000000000122,7.590400000000045,-19.233000000000175,-5.2051000000001295,-2.519999999999982,-2.365600000000086,-30.208399999999983,-13.839699999999993,45.668499999999995,16.94710000000009,-10.78950000000009,-22.88670000000002,4.853700000000117,5.919300000000021,-10.237700000000132,-8.070799999999963,-1.2171999999998206,-11.723899999999958,3.5963000000001557,-17.71239999999989,-64.76240000000007,13.241999999999962,-6.474500000000035,2.8480999999999312,30.460599999999886,21.639499999999998,-1.4934000000000651,4.527299999999968,11.089699999999993,-0.4030999999999949,6.080300000000079,17.263299999999845,3.2567999999998847,6.828600000000051,16.075700000000097,-7.873499999999922,-29.025300000000016,-11.42060000000015,0.12269999999989523,8.642500000000155,15.804800000000114,19.74369999999999,10.260499999999865,12.542099999999891,-17.898500000000013,9.913699999999835,18.513400000000047,1.0943999999999505,3.9288000000001375,2.778799999999819,3.9852999999998246,-10.41780000000017,0.4075000000000273,-15.30320000000006,2.65300000000002,11.776700000000119,-10.027199999999993,-5.927900000000136,115.3601000000001,0.2458000000001448,-15.491899999999987,-17.688199999999824,-8.682099999999991,-19.88149999999996,-44.496200000000044,5.517100000000028,10.29060000000004,33.77600000000007,-19.165700000000015,-13.628099999999904,18.990299999999934,-30.31600000000003,-9.614199999999983,15.00909999999999,23.620499999999993,-16.81880000000001,8.657999999999902,-4.326800000000048,-35.94839999999999,4.3120000000001255,4.421899999999823,4.9237000000000535,21.24479999999994,-1.442600000000084,-22.74869999999987,15.096900000000005,19.89520000000016,-0.28559999999993124,-0.34189999999989595,-1.1411000000000513,15.615999999999985,12.932000000000016,8.349500000000035,-21.426300000000083,-0.10459999999989122,3.0790000000001783,3.434500000000071,-8.03189999999995,0.4692999999999756,-13.027299999999968,14.529800000000023,0.17660000000000764,-16.568100000000186,-10.582900000000109,-13.354500000000144,-31.851499999999987,12.227499999999964,11.380300000000034,5.417000000000144,-16.405399999999872,9.803199999999833,9.900000000000091,6.655899999999974,4.331400000000031,14.046399999999949,7.065800000000081,11.616199999999935,-10.795000000000073,0.7635000000000218,-5.366600000000062,17.157600000000002,-10.304900000000089,7.939000000000078,26.706699999999955,-28.9063000000001,-3.8623000000000047,-3.5901000000001204,13.695500000000038,5.924199999999928,5.197699999999941,0.20939999999995962,14.999699999999848,3.046999999999798,-15.0003999999999,-3.0061000000000604,-14.62869999999998,16.051100000000133,25.221499999999878,-14.794200000000046,-7.451199999999972,-15.330400000000054,-4.381600000000162,-19.134700000000066,12.884700000000066,8.651200000000017,-0.3887999999999465,-8.186199999999872,-16.998799999999846,2.8922000000000025,14.13760000000002,11.331000000000131,13.973899999999958,3.5815000000000055,1.1193000000000666,-1.0832000000000335,2.475400000000036,-15.8121000000001,13.495000000000118,-4.890600000000177,-3.5108000000000175,2.9968999999998687,-7.412000000000035,-3.992100000000164,-18.12570000000005,16.280500000000075,-5.814399999999978,-16.3458999999998,-0.2843000000000302,30.43029999999999,-5.946399999999812,20.91229999999996,0.5482999999999265,12.157199999999875,16.1715999999999,9.680000000000064,7.116899999999987,-10.523699999999963,-8.036000000000058,10.75500000000011,29.613700000000108,4.976000000000113,-0.8617999999999029,-3.705299999999852,-23.25299999999993,-51.25019999999995,12.410200000000032,7.420000000000073,-1.8173000000001593,-22.816800000000057,47.377500000000055,-34.87239999999997,-16.117700000000013,23.59960000000001,5.7473999999999705,30.60030000000006,2.395999999999958,3.5400999999999385,-1.6838000000000193,-10.103399999999965,-7.948799999999892,6.389000000000124,-8.834099999999808,-33.5630000000001,-71.93820000000005,-36.018100000000004,-9.25369999999998,-77.03629999999998,18.74479999999994,57.391599999999926,-35.981599999999844,42.459699999999884,-57.85570000000007,-35.64339999999993,-82.68100000000004,61.094100000000026,-52.64969999999994,-93.67779999999993,99.86419999999998,-111.93860000000018,22.08089999999993,-10.335800000000063,20.76559999999995,-27.819600000000037,-2.5752000000002226,76.97129999999993,-3.0137999999999465,50.9991,-36.899599999999964,31.896199999999908,31.76279999999997,-42.152900000000045,3.191899999999805,-0.1978999999998905,78.04950000000008,18.285000000000082,19.07619999999997,12.802799999999934,19.668899999999894,39.04989999999998,16.917899999999918,-19.857700000000023,27.550199999999904,-24.4833000000001,-44.96250000000009,53.43810000000008,1.5324000000000524,23.206199999999853,-22.99169999999981,-36.863599999999906,96.51659999999993,25.076900000000023,-20.680700000000115,-14.306100000000015,41.3134,-22.6866,29.665399999999863,1.6382999999998447,24.44139999999993,-19.3116,-48.87850000000003,18.082800000000134,-1.5778000000000247,15.578400000000101,-24.963799999999992,39.94959999999992,8.248499999999922,-11.179899999999861,19.055000000000064,-19.08789999999999,0.5463999999999487,-3.1539000000000215,8.989199999999983,17.46810000000005,-20.66529999999989,-13.711699999999837,4.970600000000104,12.071999999999889,-4.797799999999825,15.194499999999834,-51.5929000000001,-12.72219999999993,19.01599999999985,5.051200000000108,12.541499999999814,-28.344699999999875,-0.9945000000000164,32.55489999999986,-2.8075999999998658,-20.74070000000006,-12.466300000000047,-78.92729999999983,17.094299999999976,27.642899999999827,39.67820000000006,14.479900000000043,45.65039999999999,-27.54399999999987,13.24739999999997,-1.238800000000083,34.61030000000005,-17.142900000000054,-10.841700000000174,3.246900000000096,-14.666400000000067,-0.13959999999997308,32.99199999999996,-1.5714000000000397,21.692999999999984,-70.21759999999995,0.11379999999985557,0.5628000000001521,-25.86130000000003,1.7890999999999622,14.942299999999932,-34.52340000000004,-24.840099999999893,-1.3843999999999141,-6.804399999999987,32.61299999999983,-19.413099999999986,5.323599999999942,-0.003100000000131331,13.927299999999832,22.875400000000127,-25.20139999999992,12.12869999999998,26.01969999999983,-4.59940000000006,48.35750000000007,-12.360799999999927,14.155500000000075,4.036000000000058,45.6567,-34.27930000000015,9.572499999999991,2.2489000000000487,11.453899999999976,74.57079999999996,-99.78820000000019,-62.575399999999945,-80.61259999999993,21.188000000000102,-7.936699999999973,-22.998499999999922,3.8624999999999545,15.705000000000155,-16.963899999999967,-38.419000000000096,-36.58829999999989,-15.131199999999808,26.217200000000048,-38.9541999999999,4.956899999999905,23.361699999999928,14.520299999999907,10.193899999999985,17.73219999999992,12.574899999999843,-20.596399999999903,17.83750000000009,-27.244699999999966,-4.287199999999984,28.915899999999965,47.97379999999998,47.651600000000144,16.62160000000017,-15.141100000000051,-8.117799999999988,-0.06430000000000291,-39.282700000000204,30.80690000000004,28.002199999999903,34.931699999999864,16.165500000000065,-48.13850000000002,-5.809199999999919,-88.16090000000008,52.955400000000054,47.19859999999994,19.726599999999962,13.809300000000121,103.72510000000011,4.52579999999989,-1.930599999999913,2.1554000000000997,-41.494699999999966,16.33979999999997,-16.953500000000076,23.516799999999876,-10.173900000000003,-12.03729999999996,-22.578300000000127,-0.9424999999998818,-14.51039999999989,-21.99240000000009,30.004100000000108,-8.418499999999995,22.662500000000136,-26.859899999999925,18.503999999999905,39.98610000000008,-11.466799999999921,-5.404299999999921,-23.10609999999997,-3.080699999999979,-29.362699999999904,-29.37610000000018,12.142000000000053,-30.374000000000024,1.927699999999959,-14.672199999999975,-14.474699999999984,-9.52299999999991,-7.125700000000052,-7.633100000000013,2.1445000000001073,4.579199999999901,29.72939999999994,-11.724199999999882,-11.648300000000063,-3.4625999999998385,-14.955500000000029,4.915400000000091,-7.227000000000089,42.64720000000011,28.67060000000015,-29.307199999999966,-39.09180000000015,13.423800000000028,-20.04819999999995,-7.5832000000000335,43.80579999999986,105.74250000000006,24.825000000000045,-7.167400000000043,1.8822999999999865,7.454600000000028,-92.48019999999997,6.981499999999869,-25.210800000000063,76.8107,17.05230000000006,148.77360000000022,-6.513300000000072,28.254899999999907,-30.008800000000065,-15.60069999999996,15.678699999999935,-18.813900000000103,2.416400000000067,9.567000000000007,-0.18659999999999854,-36.18170000000009,-22.135299999999916,-32.772599999999784,-14.447499999999764,20.89519999999993,-68.05199999999991,-4.964200000000119,25.63040000000001,-2.673699999999826,-41.02230000000009,3.0540000000000873,58.61419999999998,-80.24379999999974,15.67959999999971,-15.001199999999699,61.022599999999784,-36.07060000000001,-16.225700000000415,21.3746000000001,5.138799999999719,-62.83769999999981,-16.611000000000104,-5.02800000000002,30.041400000000067,-20.685899999999947,-5.815000000000282,-2.6403000000000247,16.546299999999746,-16.822099999999864,12.364700000000084,85.27550000000019,80.59979999999996,-0.2739000000001397,27.261799999999766,8.29340000000002,-2.917699999999968,-37.30139999999983,17.059999999999945,-30.356199999999717,33.67619999999988,5.979000000000269,-4.358999999999924,-32.847999999999956,-7.182299999999941,-18.69399999999996,28.795900000000074,7.341899999999896,-15.876299999999901,62.99059999999963,33.261799999999766,-22.70490000000018,-11.004599999999755,-63.50640000000021,-10.764900000000125,28.153999999999996,8.899199999999837,-77.6259,-41.881099999999606,-64.02620000000024,3.490799999999581,51.0302999999999,16.70029999999997,-23.86130000000003,-11.340599999999995,46.513400000000274,5.048199999999724,44.27210000000014,-1.942700000000059,null,null,null,null,null,null,null,null,null,null,null,null],\"type\":\"scattergl\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"showlegend\":true,\"title\":{\"text\":\"Actual vs. Residuals\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fb860291-7164-4962-8096-290b030494c3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "holdout_pred = predict_model(best_model)\n",
        "holdout_pred.head()\n",
        "predict_model(best_model, fh = 36)\n",
        "save_model(best_model, 'my_first_pipeline')\n",
        "loaded_best_pipeline = load_model('my_first_pipeline')\n",
        "loaded_best_pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Fjg4EUcqSxE-",
        "outputId": "469c5102-59c0-4bc8-e0f5-b874bdee05b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cf12eac8b20>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_36a92\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_36a92_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_36a92_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
              "      <th id=\"T_36a92_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
              "      <th id=\"T_36a92_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
              "      <th id=\"T_36a92_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
              "      <th id=\"T_36a92_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
              "      <th id=\"T_36a92_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
              "      <th id=\"T_36a92_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_36a92_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_36a92_row0_col0\" class=\"data row0 col0\" >Exponential Smoothing</td>\n",
              "      <td id=\"T_36a92_row0_col1\" class=\"data row0 col1\" >0.6004</td>\n",
              "      <td id=\"T_36a92_row0_col2\" class=\"data row0 col2\" >0.5188</td>\n",
              "      <td id=\"T_36a92_row0_col3\" class=\"data row0 col3\" >22.4597</td>\n",
              "      <td id=\"T_36a92_row0_col4\" class=\"data row0 col4\" >27.7701</td>\n",
              "      <td id=\"T_36a92_row0_col5\" class=\"data row0 col5\" >0.0091</td>\n",
              "      <td id=\"T_36a92_row0_col6\" class=\"data row0 col6\" >0.0091</td>\n",
              "      <td id=\"T_36a92_row0_col7\" class=\"data row0 col7\" >0.5251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n",
            "Transformation Pipeline and Model Successfully Loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ForecastingPipeline(steps=[('forecaster',\n",
              "                            TransformedTargetForecaster(steps=[('model',\n",
              "                                                                ExponentialSmoothing(seasonal='mul',\n",
              "                                                                                     sp=7,\n",
              "                                                                                     trend='add'))]))])"
            ],
            "text/html": [
              "<style>#sk-2474c1be-4257-4dd6-adee-3b1610ab862b {color: black;background-color: white;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b pre{padding: 0;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-toggleable {background-color: white;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-estimator:hover {background-color: #d4ebff;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-item {z-index: 1;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-parallel-item:only-child::after {width: 0;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-2474c1be-4257-4dd6-adee-3b1610ab862b div.sk-text-repr-fallback {display: none;}</style><div id='sk-2474c1be-4257-4dd6-adee-3b1610ab862b' class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ForecastingPipeline(steps=[(&#x27;forecaster&#x27;,\n",
              "                            TransformedTargetForecaster(steps=[(&#x27;model&#x27;,\n",
              "                                                                ExponentialSmoothing(seasonal=&#x27;mul&#x27;,\n",
              "                                                                                     sp=7,\n",
              "                                                                                     trend=&#x27;add&#x27;))]))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class='sk-label-container'><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('33e1ee08-348c-4607-89e6-2459721add9c') type=\"checkbox\" ><label for=UUID('33e1ee08-348c-4607-89e6-2459721add9c') class='sk-toggleable__label sk-toggleable__label-arrow'>ForecastingPipeline</label><div class=\"sk-toggleable__content\"><pre>ForecastingPipeline(steps=[(&#x27;forecaster&#x27;,\n",
              "                            TransformedTargetForecaster(steps=[(&#x27;model&#x27;,\n",
              "                                                                ExponentialSmoothing(seasonal=&#x27;mul&#x27;,\n",
              "                                                                                     sp=7,\n",
              "                                                                                     trend=&#x27;add&#x27;))]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('5ebdff23-2b41-4f66-a9d7-c2f82a0142e0') type=\"checkbox\" ><label for=UUID('5ebdff23-2b41-4f66-a9d7-c2f82a0142e0') class='sk-toggleable__label sk-toggleable__label-arrow'>ExponentialSmoothing</label><div class=\"sk-toggleable__content\"><pre>ExponentialSmoothing(seasonal=&#x27;mul&#x27;, sp=7, trend=&#x27;add&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}